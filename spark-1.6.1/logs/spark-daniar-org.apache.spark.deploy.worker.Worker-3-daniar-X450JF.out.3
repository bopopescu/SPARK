/usr/lib/jvm/java-8-oracle/
DANIAR
NOTE: SPARK_PREPEND_CLASSES is set, placing locally compiled Spark classes ahead of assembly.
Spark Command: /usr/lib/jvm/java-8-oracle//bin/java -cp /home/daniar/documents/SPARK/spark-1.6.1/conf/:/home/daniar/documents/SPARK/spark-1.6.1/core/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/repl/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/mllib/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/bagel/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/graphx/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/streaming/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/tools/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/catalyst/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/core/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/hive/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/hive-thriftserver/target/scala-2.10/classes:/home/daniar/documents/SPARK/spark-1.6.1/yarn/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/launcher/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/common/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/shuffle/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/yarn/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/core/target/jars/*:/home/daniar/documents/SPARK/spark-1.6.1/assembly/target/scala-2.10/spark-assembly-1.6.1-hadoop2.7.2.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar -Xms1g -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8083 spark://192.168.1.3:7077 --host 192.168.1.12 --memory 1g --cores 1
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/06/18 10:39:04 INFO Worker: Registered signal handlers for [TERM, HUP, INT]
16/06/18 10:39:04 WARN Utils: Your hostname, daniar-X450JF resolves to a loopback address: 127.0.1.1; using 192.168.1.12 instead (on interface wlan0)
16/06/18 10:39:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
16/06/18 10:39:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/18 10:39:05 INFO SecurityManager: Changing view acls to: daniar
16/06/18 10:39:05 INFO SecurityManager: Changing modify acls to: daniar
16/06/18 10:39:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(daniar); users with modify permissions: Set(daniar)
16/06/18 10:39:05 INFO Utils: Successfully started service 'sparkWorker' on port 60761.
16/06/18 10:39:06 INFO Worker: Starting Spark worker 192.168.1.12:60761 with 1 cores, 1024.0 MB RAM
16/06/18 10:39:06 INFO Worker: Running Spark version 1.6.1
16/06/18 10:39:06 INFO Worker: Spark home: /home/daniar/documents/SPARK/spark-1.6.1
16/06/18 10:39:06 INFO Server: jetty-8.y.z-SNAPSHOT
16/06/18 10:39:06 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:8083
16/06/18 10:39:06 INFO Utils: Successfully started service 'WorkerUI' on port 8083.
16/06/18 10:39:06 INFO WorkerWebUI: Started WorkerWebUI at http://192.168.1.12:8083
16/06/18 10:39:06 INFO Worker: Connecting to master 192.168.1.3:7077...
16/06/18 10:39:06 INFO Worker: Successfully registered with master spark://192.168.1.3:7077
16/06/18 10:42:32 INFO Worker: Asked to launch executor app-20160618104232-0000/2 for Sort5
16/06/18 10:42:32 INFO SecurityManager: Changing view acls to: daniar
16/06/18 10:42:32 INFO SecurityManager: Changing modify acls to: daniar
16/06/18 10:42:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(daniar); users with modify permissions: Set(daniar)
NOTE: SPARK_PREPEND_CLASSES is set, placing locally compiled Spark classes ahead of assembly.
16/06/18 10:42:32 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-8-oracle//bin/java" "-cp" "/home/daniar/documents/SPARK/spark-1.6.1/conf/:/home/daniar/documents/SPARK/spark-1.6.1/core/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/repl/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/mllib/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/bagel/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/graphx/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/streaming/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/tools/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/catalyst/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/core/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/hive/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/hive-thriftserver/target/scala-2.10/classes:/home/daniar/documents/SPARK/spark-1.6.1/yarn/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/launcher/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/common/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/shuffle/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/yarn/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/core/target/jars/*:/home/daniar/documents/SPARK/spark-1.6.1/assembly/target/scala-2.10/spark-assembly-1.6.1-hadoop2.7.2.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar" "-Xms1024M" "-Xmx1024M" "-Dspark.driver.port=60918" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.12:60918" "--executor-id" "2" "--hostname" "192.168.1.12" "--cores" "1" "--app-id" "app-20160618104232-0000" "--worker-url" "spark://Worker@192.168.1.12:60761"
16/06/18 10:44:14 ERROR Worker: RECEIVED SIGNAL 15: SIGTERM
16/06/18 10:44:14 INFO ExecutorRunner: Killing process!
16/06/18 10:44:14 INFO Worker: Executor app-20160618104232-0000/2 finished with state EXITED message Command exited with code 137 exitStatus 137
16/06/18 10:44:14 INFO ShutdownHookManager: Shutdown hook called
16/06/18 10:44:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-aeaa874c-99ae-498a-9ef0-a47678d8e627
16/06/18 10:44:14 INFO Worker: Unknown Executor app-20160618104232-0000/2 finished with state EXITED message Worker shutting down exitStatus 137
