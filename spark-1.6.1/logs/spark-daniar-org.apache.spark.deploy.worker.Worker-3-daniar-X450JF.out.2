/usr/lib/jvm/java-8-oracle/
DANIAR
NOTE: SPARK_PREPEND_CLASSES is set, placing locally compiled Spark classes ahead of assembly.
Spark Command: /usr/lib/jvm/java-8-oracle//bin/java -cp /home/daniar/documents/SPARK/spark-1.6.1/conf/:/home/daniar/documents/SPARK/spark-1.6.1/core/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/repl/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/mllib/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/bagel/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/graphx/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/streaming/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/tools/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/catalyst/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/core/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/hive/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/hive-thriftserver/target/scala-2.10/classes:/home/daniar/documents/SPARK/spark-1.6.1/yarn/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/launcher/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/common/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/shuffle/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/yarn/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/core/target/jars/*:/home/daniar/documents/SPARK/spark-1.6.1/assembly/target/scala-2.10/spark-assembly-1.6.1-hadoop2.7.2.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar -Xms1g -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8083 spark://192.168.1.3:7077 --host 192.168.1.12 --memory 1g --cores 3
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/06/18 10:45:59 INFO Worker: Registered signal handlers for [TERM, HUP, INT]
16/06/18 10:45:59 WARN Utils: Your hostname, daniar-X450JF resolves to a loopback address: 127.0.1.1; using 192.168.1.12 instead (on interface wlan0)
16/06/18 10:45:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
16/06/18 10:46:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/18 10:46:00 INFO SecurityManager: Changing view acls to: daniar
16/06/18 10:46:00 INFO SecurityManager: Changing modify acls to: daniar
16/06/18 10:46:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(daniar); users with modify permissions: Set(daniar)
16/06/18 10:46:00 INFO Utils: Successfully started service 'sparkWorker' on port 34710.
16/06/18 10:46:00 INFO Worker: Starting Spark worker 192.168.1.12:34710 with 3 cores, 1024.0 MB RAM
16/06/18 10:46:00 INFO Worker: Running Spark version 1.6.1
16/06/18 10:46:00 INFO Worker: Spark home: /home/daniar/documents/SPARK/spark-1.6.1
16/06/18 10:46:00 INFO Server: jetty-8.y.z-SNAPSHOT
16/06/18 10:46:00 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:8083
16/06/18 10:46:00 INFO Utils: Successfully started service 'WorkerUI' on port 8083.
16/06/18 10:46:00 INFO WorkerWebUI: Started WorkerWebUI at http://192.168.1.12:8083
16/06/18 10:46:00 INFO Worker: Connecting to master 192.168.1.3:7077...
16/06/18 10:46:00 INFO Worker: Successfully registered with master spark://192.168.1.3:7077
16/06/18 10:46:34 INFO Worker: Asked to launch executor app-20160618104634-0000/0 for Sort5
16/06/18 10:46:34 INFO SecurityManager: Changing view acls to: daniar
16/06/18 10:46:34 INFO SecurityManager: Changing modify acls to: daniar
16/06/18 10:46:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(daniar); users with modify permissions: Set(daniar)
NOTE: SPARK_PREPEND_CLASSES is set, placing locally compiled Spark classes ahead of assembly.
16/06/18 10:46:34 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-8-oracle//bin/java" "-cp" "/home/daniar/documents/SPARK/spark-1.6.1/conf/:/home/daniar/documents/SPARK/spark-1.6.1/core/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/repl/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/mllib/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/bagel/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/graphx/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/streaming/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/tools/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/catalyst/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/core/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/hive/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/sql/hive-thriftserver/target/scala-2.10/classes:/home/daniar/documents/SPARK/spark-1.6.1/yarn/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/launcher/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/common/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/shuffle/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/network/yarn/target/scala-2.10/classes/:/home/daniar/documents/SPARK/spark-1.6.1/core/target/jars/*:/home/daniar/documents/SPARK/spark-1.6.1/assembly/target/scala-2.10/spark-assembly-1.6.1-hadoop2.7.2.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-core-3.2.10.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/home/daniar/documents/SPARK/spark-1.6.1/lib_managed/jars/datanucleus-rdbms-3.2.9.jar" "-Xms1024M" "-Xmx1024M" "-Dspark.driver.port=56587" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.12:56587" "--executor-id" "0" "--hostname" "192.168.1.12" "--cores" "3" "--app-id" "app-20160618104634-0000" "--worker-url" "spark://Worker@192.168.1.12:34710"
16/06/18 10:49:10 INFO Worker: Asked to kill executor app-20160618104634-0000/0
16/06/18 10:49:10 INFO ExecutorRunner: Runner thread for executor app-20160618104634-0000/0 interrupted
16/06/18 10:49:10 INFO ExecutorRunner: Killing process!
16/06/18 10:49:10 INFO Worker: Executor app-20160618104634-0000/0 finished with state KILLED exitStatus 137
16/06/18 10:49:10 INFO Worker: Cleaning up local directories for application app-20160618104634-0000
16/06/18 10:49:10 INFO ExternalShuffleBlockResolver: Application app-20160618104634-0000 removed, cleanupLocalDirs = true
16/06/18 12:09:20 ERROR Worker: RECEIVED SIGNAL 15: SIGTERM
16/06/18 12:09:20 INFO ShutdownHookManager: Shutdown hook called
16/06/18 12:09:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-3f05fec2-bd6c-487a-9e01-9ca0f287e48c
