[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/SparkContext.scala:186: constructor SparkContext in class SparkContext is deprecated: Passing in preferred locations has no effect at all, see SPARK-10921[0m
[0m[[33mwarn[0m] [0m    this(master, appName, null, Nil, Map())[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/SparkContext.scala:196: constructor SparkContext in class SparkContext is deprecated: Passing in preferred locations has no effect at all, see SPARK-10921[0m
[0m[[33mwarn[0m] [0m    this(master, appName, sparkHome, Nil, Map())[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/SparkContext.scala:208: constructor SparkContext in class SparkContext is deprecated: Passing in preferred locations has no effect at all, see SPARK-10921[0m
[0m[[33mwarn[0m] [0m    this(master, appName, sparkHome, jars, Map())[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/SparkContext.scala:871: constructor Job in class Job is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    val job = new NewHadoopJob(hadoopConfiguration)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/SparkContext.scala:920: constructor Job in class Job is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    val job = new NewHadoopJob(hadoopConfiguration)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/SparkContext.scala:1099: constructor Job in class Job is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    val job = new NewHadoopJob(conf)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/SparkContext.scala:1366: method isDir in class FileStatus is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      val isDir = fs.getFileStatus(hadoopPath).isDir[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/deploy/SparkHadoopUtil.scala:236: method isDir in class FileStatus is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      val (directories, leaves) = fs.listStatus(status.getPath).partition(_.isDir)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/deploy/SparkHadoopUtil.scala:240: method isDir in class FileStatus is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    if (baseStatus.isDir) recurse(baseStatus) else Seq(baseStatus)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/deploy/SparkHadoopUtil.scala:249: method isDir in class FileStatus is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      val (directories, files) = fs.listStatus(status.getPath).partition(_.isDir)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/deploy/SparkHadoopUtil.scala:254: method isDir in class FileStatus is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    assert(baseStatus.isDir)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/scheduler/InputFormatInfo.scala:106: constructor Job in class Job is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    val job = new Job(conf)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/input/WholeTextFileInputFormat.scala:56: method isDir in class FileStatus is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    val totalLen = files.map(file => if (file.isDir) 0L else file.getLen).sum[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/SparkEnv.scala:101: value actorSystem in class SparkEnv is deprecated: Actor system is no longer supported as of 1.4.0[0m
[0m[[33mwarn[0m] [0m        actorSystem.shutdown()[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:104: value TRY_CACHE in object WriteType is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    val os = file.getOutStream(WriteType.TRY_CACHE)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:118: value TRY_CACHE in object WriteType is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    val os = file.getOutStream(WriteType.TRY_CACHE)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:47: class TachyonFS in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  var client: tachyon.client.TachyonFS = _[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:53: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  private var tachyonDirs: Array[TachyonFile] = _[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:54: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  private var subDirs: Array[Array[tachyon.client.TachyonFile]] = _[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:82: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    subDirs = Array.fill(tachyonDirs.length)(new Array[TachyonFile](subDirsPerTachyonDir))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:165: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def removeFile(file: TachyonFile): Boolean = {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:169: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def fileExists(file: TachyonFile): Boolean = {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:173: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def getFile(filename: String): TachyonFile = {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:203: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def getFile(blockId: BlockId): TachyonFile = getFile(blockId.name)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:206: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  private def createTachyonDirs(): Array[TachyonFile] = {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/storage/TachyonBlockManager.scala:211: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      var tachyonDir: TachyonFile = null[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/util/ShutdownHookManager.scala:81: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def registerShutdownDeleteDir(tachyonfile: TachyonFile) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/util/ShutdownHookManager.scala:97: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def removeShutdownDeleteDir(tachyonfile: TachyonFile) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/util/ShutdownHookManager.scala:113: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def hasShutdownDeleteTachyonDir(file: TachyonFile): Boolean = {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/util/ShutdownHookManager.scala:139: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def hasRootAsShutdownDeleteDir(file: TachyonFile): Boolean = {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/rdd/HadoopRDD.scala:360: constructor TaskID in class TaskID is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    val taId = new TaskAttemptID(new TaskID(jobID, true, splitId), attemptId)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/SparkHadoopWriter.scala:153: constructor TaskID in class TaskID is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m        new TaskAttemptID(new TaskID(jID.value, true, splitID), attemptID))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/SparkHadoopWriter.scala:174: method makeQualified in class Path is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    outputPath.makeQualified(fs)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/input/PortableDataStream.scala:46: method isDir in class FileStatus is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    val totalLen = listStatus(context).asScala.filterNot(_.isDir).map(_.getLen).sum[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/deploy/history/FsHistoryProvider.scala:170: method isDir in class FileStatus is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    if (!fs.getFileStatus(path).isDir) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/deploy/history/FsHistoryProvider.scala:307: method delete in class FileSystem is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      if (!fs.delete(path)) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/deploy/history/FsHistoryProvider.scala:606: method isDir in class FileStatus is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  private def isLegacyLogDirectory(entry: FileStatus): Boolean = entry.isDir()[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/rdd/ReliableCheckpointRDD.scala:177: method getDefaultReplication in class FileSystem is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m      fs.create(tempOutputPath, false, bufferSize, fs.getDefaultReplication, blockSize)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/scheduler/EventLoggingListener.scala:100: method isDir in class FileStatus is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    if (!fileSystem.getFileStatus(new Path(logBaseDir)).isDir) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/api/java/JavaSparkContext.scala:105: constructor SparkContext in class SparkContext is deprecated: Passing in preferred locations has no effect at all, see SPARK-10921[0m
[0m[[33mwarn[0m] [0m    this(new SparkContext(master, appName, sparkHome, jars.toSeq, environment.asScala, Map()))[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/rdd/PairRDDFunctions.scala:988: constructor Job in class Job is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    val job = new NewAPIHadoopJob(hadoopConf)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/rdd/PairRDDFunctions.scala:1077: constructor Job in class Job is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    val job = new NewAPIHadoopJob(hadoopConf)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/mapred/SparkHadoopMapRedUtil.scala:64: constructor TaskAttemptID in class TaskAttemptID is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m    new TaskAttemptID(jtIdentifier, jobId, isMap, taskId, attemptId)[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/util/Utils.scala:938: class TachyonFile in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def deleteRecursively(dir: TachyonFile, client: TachyonFS) {[0m
[0m[[33mwarn[0m] [0m[0m
[0m[[33mwarn[0m] [0m/home/daniar/documents/testing/test4/SPARK/spark-1.6.1/core/src/main/scala/org/apache/spark/util/Utils.scala:938: class TachyonFS in package client is deprecated: see corresponding Javadoc for more information.[0m
[0m[[33mwarn[0m] [0m  def deleteRecursively(dir: TachyonFile, client: TachyonFS) {[0m
[0m[[33mwarn[0m] [0m[0m
