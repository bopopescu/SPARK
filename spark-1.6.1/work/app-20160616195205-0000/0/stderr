Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/06/16 19:52:06 INFO CoarseGrainedExecutorBackend: Registered signal handlers for [TERM, HUP, INT]
16/06/16 19:52:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/16 19:52:07 INFO SecurityManager: Changing view acls to: daniar
16/06/16 19:52:07 INFO SecurityManager: Changing modify acls to: daniar
16/06/16 19:52:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(daniar); users with modify permissions: Set(daniar)
16/06/16 19:52:07 INFO SecurityManager: Changing view acls to: daniar
16/06/16 19:52:07 INFO SecurityManager: Changing modify acls to: daniar
16/06/16 19:52:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(daniar); users with modify permissions: Set(daniar)
16/06/16 19:52:08 INFO Slf4jLogger: Slf4jLogger started
16/06/16 19:52:08 INFO Remoting: Starting remoting
16/06/16 19:52:08 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@192.168.1.12:38407]
16/06/16 19:52:08 INFO Utils: Successfully started service 'sparkExecutorActorSystem' on port 38407.
16/06/16 19:52:08 INFO DiskBlockManager: Created local directory at /tmp/spark-11c846c9-7995-4950-9f9d-4a201b1bfeda/executor-84673349-e7b1-494b-b79d-0dad961fd33a/blockmgr-8d17bd9b-1d4c-40ea-8cd8-1a1c5b8f94c5
16/06/16 19:52:08 INFO MemoryStore: MemoryStore started with capacity 511.1 MB
16/06/16 19:52:08 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.1.12:54127
16/06/16 19:52:08 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.1.12:32953
16/06/16 19:52:08 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
16/06/16 19:52:08 INFO Executor: Starting executor ID 0 on host 192.168.1.10
16/06/16 19:52:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49405.
16/06/16 19:52:08 INFO NettyBlockTransferService: Server created on 49405
16/06/16 19:52:08 INFO BlockManagerMaster: Trying to register BlockManager
16/06/16 19:52:08 INFO BlockManagerMaster: Registered BlockManager
16/06/16 19:52:09 INFO CoarseGrainedExecutorBackend: Got assigned task 0
16/06/16 19:52:09 INFO CoarseGrainedExecutorBackend: Got assigned task 1
16/06/16 19:52:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/06/16 19:52:09 INFO CoarseGrainedExecutorBackend: Got assigned task 2
16/06/16 19:52:09 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/06/16 19:52:09 INFO CoarseGrainedExecutorBackend: Got assigned task 3
16/06/16 19:52:09 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
16/06/16 19:52:09 INFO CoarseGrainedExecutorBackend: Got assigned task 4
16/06/16 19:52:09 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
16/06/16 19:52:09 INFO CoarseGrainedExecutorBackend: Got assigned task 5
16/06/16 19:52:09 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
16/06/16 19:52:09 INFO CoarseGrainedExecutorBackend: Got assigned task 6
16/06/16 19:52:09 INFO CoarseGrainedExecutorBackend: Got assigned task 7
16/06/16 19:52:09 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
16/06/16 19:52:09 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
16/06/16 19:52:09 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
16/06/16 19:52:09 INFO Executor: Fetching http://192.168.1.12:35488/files/sort.py with timestamp 1466081525378
16/06/16 19:52:09 INFO Utils: Fetching http://192.168.1.12:35488/files/sort.py to /tmp/spark-11c846c9-7995-4950-9f9d-4a201b1bfeda/executor-84673349-e7b1-494b-b79d-0dad961fd33a/spark-cfdb60ca-0c64-4fa9-ad58-29dad88ca4f7/fetchFileTemp6682598751528356969.tmp
16/06/16 19:52:09 INFO Utils: Copying /tmp/spark-11c846c9-7995-4950-9f9d-4a201b1bfeda/executor-84673349-e7b1-494b-b79d-0dad961fd33a/spark-cfdb60ca-0c64-4fa9-ad58-29dad88ca4f7/5553896571466081525378_cache to /home/daniar/documents/SPARK/spark-1.6.1/work/app-20160616195205-0000/0/./sort.py
16/06/16 19:52:09 INFO TorrentBroadcast: Started reading broadcast variable 1
16/06/16 19:52:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 3.7 KB)
16/06/16 19:52:09 INFO TorrentBroadcast: Reading broadcast variable 1 took 163 ms
16/06/16 19:52:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.1 KB, free 9.8 KB)
16/06/16 19:52:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:16566599+2366657
16/06/16 19:52:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:0+2366657
16/06/16 19:52:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:14199942+2366657
16/06/16 19:52:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:11833285+2366657
16/06/16 19:52:10 INFO TorrentBroadcast: Started reading broadcast variable 0
16/06/16 19:52:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:2366657+2366657
16/06/16 19:52:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:4733314+2366657
16/06/16 19:52:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:7099971+2366657
16/06/16 19:52:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:9466628+2366657
16/06/16 19:52:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.8 KB, free 31.6 KB)
16/06/16 19:52:10 INFO TorrentBroadcast: Reading broadcast variable 0 took 17 ms
16/06/16 19:52:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 315.4 KB, free 347.0 KB)
16/06/16 19:52:10 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
16/06/16 19:52:10 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
16/06/16 19:52:10 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
16/06/16 19:52:10 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
16/06/16 19:52:10 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
16/06/16 19:52:19 INFO PythonRunner: Times: total = 8701, boot = 275, init = 117, finish = 8309
16/06/16 19:52:19 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2130 bytes result sent to driver
16/06/16 19:52:19 INFO CoarseGrainedExecutorBackend: Got assigned task 26
16/06/16 19:52:19 INFO Executor: Running task 26.0 in stage 0.0 (TID 26)
16/06/16 19:52:19 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:61533082+2366657
16/06/16 19:52:19 INFO PythonRunner: Times: total = 8927, boot = 251, init = 155, finish = 8521
16/06/16 19:52:19 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 2130 bytes result sent to driver
16/06/16 19:52:19 INFO CoarseGrainedExecutorBackend: Got assigned task 31
16/06/16 19:52:19 INFO Executor: Running task 31.0 in stage 0.0 (TID 31)
16/06/16 19:52:19 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:73366367+2366657
16/06/16 19:52:19 INFO PythonRunner: Times: total = 9163, boot = 235, init = 231, finish = 8697
16/06/16 19:52:19 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 2130 bytes result sent to driver
16/06/16 19:52:19 INFO CoarseGrainedExecutorBackend: Got assigned task 36
16/06/16 19:52:19 INFO Executor: Running task 36.0 in stage 0.0 (TID 36)
16/06/16 19:52:20 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:85199652+2366657
16/06/16 19:52:20 INFO PythonRunner: Times: total = 9190, boot = 223, init = 165, finish = 8802
16/06/16 19:52:20 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 2130 bytes result sent to driver
16/06/16 19:52:20 INFO CoarseGrainedExecutorBackend: Got assigned task 37
16/06/16 19:52:20 INFO Executor: Running task 37.0 in stage 0.0 (TID 37)
16/06/16 19:52:20 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:87566309+2366657
16/06/16 19:52:20 INFO PythonRunner: Times: total = 9347, boot = 266, init = 318, finish = 8763
16/06/16 19:52:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2130 bytes result sent to driver
16/06/16 19:52:20 INFO CoarseGrainedExecutorBackend: Got assigned task 40
16/06/16 19:52:20 INFO Executor: Running task 40.0 in stage 0.0 (TID 40)
16/06/16 19:52:20 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:94666280+2366657
16/06/16 19:52:20 INFO PythonRunner: Times: total = 9491, boot = 215, init = 313, finish = 8963
16/06/16 19:52:20 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 2130 bytes result sent to driver
16/06/16 19:52:20 INFO PythonRunner: Times: total = 9534, boot = 190, init = 360, finish = 8984
16/06/16 19:52:20 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 2130 bytes result sent to driver
16/06/16 19:52:20 INFO CoarseGrainedExecutorBackend: Got assigned task 42
16/06/16 19:52:20 INFO Executor: Running task 42.0 in stage 0.0 (TID 42)
16/06/16 19:52:20 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:99399594+2366657
16/06/16 19:52:20 INFO CoarseGrainedExecutorBackend: Got assigned task 44
16/06/16 19:52:20 INFO Executor: Running task 44.0 in stage 0.0 (TID 44)
16/06/16 19:52:20 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:104132908+2366657
16/06/16 19:52:20 INFO PythonRunner: Times: total = 9689, boot = 268, init = 201, finish = 9220
16/06/16 19:52:20 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 2130 bytes result sent to driver
16/06/16 19:52:20 INFO CoarseGrainedExecutorBackend: Got assigned task 47
16/06/16 19:52:20 INFO Executor: Running task 47.0 in stage 0.0 (TID 47)
16/06/16 19:52:20 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:111232879+2366657
16/06/16 19:52:27 INFO PythonRunner: Times: total = 8318, boot = -75, init = 154, finish = 8239
16/06/16 19:52:27 INFO Executor: Finished task 26.0 in stage 0.0 (TID 26). 2130 bytes result sent to driver
16/06/16 19:52:27 INFO CoarseGrainedExecutorBackend: Got assigned task 50
16/06/16 19:52:27 INFO Executor: Running task 50.0 in stage 0.0 (TID 50)
16/06/16 19:52:27 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:118332850+2366657
16/06/16 19:52:28 INFO PythonRunner: Times: total = 8423, boot = 45, init = 10, finish = 8368
16/06/16 19:52:28 INFO Executor: Finished task 31.0 in stage 0.0 (TID 31). 2130 bytes result sent to driver
16/06/16 19:52:28 INFO CoarseGrainedExecutorBackend: Got assigned task 54
16/06/16 19:52:28 INFO Executor: Running task 54.0 in stage 0.0 (TID 54)
16/06/16 19:52:28 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:127799478+2366657
16/06/16 19:52:28 INFO PythonRunner: Times: total = 8411, boot = -66, init = 86, finish = 8391
16/06/16 19:52:28 INFO Executor: Finished task 40.0 in stage 0.0 (TID 40). 2130 bytes result sent to driver
16/06/16 19:52:28 INFO CoarseGrainedExecutorBackend: Got assigned task 57
16/06/16 19:52:28 INFO Executor: Running task 57.0 in stage 0.0 (TID 57)
16/06/16 19:52:28 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:134899449+2366657
16/06/16 19:52:28 INFO PythonRunner: Times: total = 8852, boot = 32, init = 7, finish = 8813
16/06/16 19:52:28 INFO Executor: Finished task 37.0 in stage 0.0 (TID 37). 2130 bytes result sent to driver
16/06/16 19:52:28 INFO CoarseGrainedExecutorBackend: Got assigned task 60
16/06/16 19:52:28 INFO Executor: Running task 60.0 in stage 0.0 (TID 60)
16/06/16 19:52:28 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:141999420+2366657
16/06/16 19:52:28 INFO PythonRunner: Times: total = 8586, boot = -52, init = 233, finish = 8405
16/06/16 19:52:29 INFO Executor: Finished task 42.0 in stage 0.0 (TID 42). 2130 bytes result sent to driver
16/06/16 19:52:29 INFO CoarseGrainedExecutorBackend: Got assigned task 62
16/06/16 19:52:29 INFO Executor: Running task 62.0 in stage 0.0 (TID 62)
16/06/16 19:52:29 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:146732734+2366657
16/06/16 19:52:29 INFO PythonRunner: Times: total = 9048, boot = 45, init = 24, finish = 8979
16/06/16 19:52:29 INFO Executor: Finished task 36.0 in stage 0.0 (TID 36). 2130 bytes result sent to driver
16/06/16 19:52:29 INFO CoarseGrainedExecutorBackend: Got assigned task 64
16/06/16 19:52:29 INFO Executor: Running task 64.0 in stage 0.0 (TID 64)
16/06/16 19:52:29 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:151466048+2366657
16/06/16 19:52:29 INFO PythonRunner: Times: total = 9180, boot = -150, init = 188, finish = 9142
16/06/16 19:52:29 INFO Executor: Finished task 44.0 in stage 0.0 (TID 44). 2130 bytes result sent to driver
16/06/16 19:52:29 INFO CoarseGrainedExecutorBackend: Got assigned task 70
16/06/16 19:52:29 INFO Executor: Running task 70.0 in stage 0.0 (TID 70)
16/06/16 19:52:29 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:165665990+2366657
16/06/16 19:52:29 INFO PythonRunner: Times: total = 9121, boot = -274, init = 470, finish = 8925
16/06/16 19:52:29 INFO Executor: Finished task 47.0 in stage 0.0 (TID 47). 2130 bytes result sent to driver
16/06/16 19:52:29 INFO CoarseGrainedExecutorBackend: Got assigned task 71
16/06/16 19:52:29 INFO Executor: Running task 71.0 in stage 0.0 (TID 71)
16/06/16 19:52:29 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:168032647+2366657
16/06/16 19:52:35 INFO PythonRunner: Times: total = 7986, boot = -17, init = 56, finish = 7947
16/06/16 19:52:35 INFO Executor: Finished task 50.0 in stage 0.0 (TID 50). 2130 bytes result sent to driver
16/06/16 19:52:35 INFO CoarseGrainedExecutorBackend: Got assigned task 72
16/06/16 19:52:35 INFO Executor: Running task 72.0 in stage 0.0 (TID 72)
16/06/16 19:52:35 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:170399304+2366657
16/06/16 19:52:36 INFO PythonRunner: Times: total = 8463, boot = -47, init = 59, finish = 8451
16/06/16 19:52:36 INFO Executor: Finished task 54.0 in stage 0.0 (TID 54). 2130 bytes result sent to driver
16/06/16 19:52:36 INFO CoarseGrainedExecutorBackend: Got assigned task 80
16/06/16 19:52:36 INFO Executor: Running task 80.0 in stage 0.0 (TID 80)
16/06/16 19:52:36 INFO PythonRunner: Times: total = 8076, boot = -32, init = 86, finish = 8022
16/06/16 19:52:36 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:189332560+2366657
16/06/16 19:52:36 INFO Executor: Finished task 57.0 in stage 0.0 (TID 57). 2130 bytes result sent to driver
16/06/16 19:52:36 INFO PythonRunner: Times: total = 7765, boot = -22, init = 94, finish = 7693
16/06/16 19:52:36 INFO Executor: Finished task 62.0 in stage 0.0 (TID 62). 2130 bytes result sent to driver
16/06/16 19:52:36 INFO CoarseGrainedExecutorBackend: Got assigned task 81
16/06/16 19:52:36 INFO CoarseGrainedExecutorBackend: Got assigned task 82
16/06/16 19:52:36 INFO Executor: Running task 81.0 in stage 0.0 (TID 81)
16/06/16 19:52:36 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:191699217+2366657
16/06/16 19:52:36 INFO Executor: Running task 82.0 in stage 0.0 (TID 82)
16/06/16 19:52:36 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:194065874+2366657
16/06/16 19:52:37 INFO PythonRunner: Times: total = 8058, boot = -130, init = 143, finish = 8045
16/06/16 19:52:37 INFO Executor: Finished task 64.0 in stage 0.0 (TID 64). 2130 bytes result sent to driver
16/06/16 19:52:37 INFO CoarseGrainedExecutorBackend: Got assigned task 86
16/06/16 19:52:37 INFO Executor: Running task 86.0 in stage 0.0 (TID 86)
16/06/16 19:52:37 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:203532502+2366657
16/06/16 19:52:37 INFO PythonRunner: Times: total = 8640, boot = -5, init = 30, finish = 8615
16/06/16 19:52:37 INFO Executor: Finished task 60.0 in stage 0.0 (TID 60). 2130 bytes result sent to driver
16/06/16 19:52:37 INFO CoarseGrainedExecutorBackend: Got assigned task 90
16/06/16 19:52:37 INFO Executor: Running task 90.0 in stage 0.0 (TID 90)
16/06/16 19:52:37 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:212999130+2366657
16/06/16 19:52:38 INFO PythonRunner: Times: total = 8676, boot = -8, init = 84, finish = 8600
16/06/16 19:52:38 INFO Executor: Finished task 71.0 in stage 0.0 (TID 71). 2130 bytes result sent to driver
16/06/16 19:52:38 INFO CoarseGrainedExecutorBackend: Got assigned task 94
16/06/16 19:52:38 INFO Executor: Running task 94.0 in stage 0.0 (TID 94)
16/06/16 19:52:38 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:222465758+2366657
16/06/16 19:52:38 INFO PythonRunner: Times: total = 8837, boot = -11, init = 55, finish = 8793
16/06/16 19:52:38 INFO Executor: Finished task 70.0 in stage 0.0 (TID 70). 2130 bytes result sent to driver
16/06/16 19:52:38 INFO CoarseGrainedExecutorBackend: Got assigned task 95
16/06/16 19:52:38 INFO Executor: Running task 95.0 in stage 0.0 (TID 95)
16/06/16 19:52:38 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:224832415+2366657
16/06/16 19:52:44 INFO PythonRunner: Times: total = 8260, boot = -12, init = 45, finish = 8227
16/06/16 19:52:44 INFO Executor: Finished task 72.0 in stage 0.0 (TID 72). 2130 bytes result sent to driver
16/06/16 19:52:44 INFO CoarseGrainedExecutorBackend: Got assigned task 96
16/06/16 19:52:44 INFO Executor: Running task 96.0 in stage 0.0 (TID 96)
16/06/16 19:52:44 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:227199072+2366657
16/06/16 19:52:44 INFO PythonRunner: Times: total = 7861, boot = -54, init = 85, finish = 7830
16/06/16 19:52:44 INFO Executor: Finished task 80.0 in stage 0.0 (TID 80). 2130 bytes result sent to driver
16/06/16 19:52:45 INFO PythonRunner: Times: total = 8329, boot = -42, init = 129, finish = 8242
16/06/16 19:52:45 INFO Executor: Finished task 82.0 in stage 0.0 (TID 82). 2130 bytes result sent to driver
16/06/16 19:52:45 INFO PythonRunner: Times: total = 8354, boot = -74, init = 97, finish = 8331
16/06/16 19:52:45 INFO Executor: Finished task 81.0 in stage 0.0 (TID 81). 2130 bytes result sent to driver
16/06/16 19:52:45 INFO PythonRunner: Times: total = 8026, boot = -2, init = 35, finish = 7993
16/06/16 19:52:45 INFO Executor: Finished task 86.0 in stage 0.0 (TID 86). 2130 bytes result sent to driver
16/06/16 19:52:45 INFO PythonRunner: Times: total = 7907, boot = 8, init = 130, finish = 7769
16/06/16 19:52:45 INFO Executor: Finished task 90.0 in stage 0.0 (TID 90). 2130 bytes result sent to driver
16/06/16 19:52:45 INFO PythonRunner: Times: total = 7158, boot = -1, init = 47, finish = 7112
16/06/16 19:52:45 INFO Executor: Finished task 94.0 in stage 0.0 (TID 94). 2130 bytes result sent to driver
16/06/16 19:52:46 INFO PythonRunner: Times: total = 7235, boot = -10, init = 57, finish = 7188
16/06/16 19:52:46 INFO Executor: Finished task 95.0 in stage 0.0 (TID 95). 2130 bytes result sent to driver
16/06/16 19:52:47 INFO PythonRunner: Times: total = 3036, boot = 35, init = 1, finish = 3000
16/06/16 19:52:47 INFO Executor: Finished task 96.0 in stage 0.0 (TID 96). 2130 bytes result sent to driver
16/06/16 19:52:47 INFO CoarseGrainedExecutorBackend: Got assigned task 100
16/06/16 19:52:47 INFO CoarseGrainedExecutorBackend: Got assigned task 103
16/06/16 19:52:47 INFO Executor: Running task 3.0 in stage 1.0 (TID 103)
16/06/16 19:52:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 100)
16/06/16 19:52:47 INFO TorrentBroadcast: Started reading broadcast variable 2
16/06/16 19:52:47 INFO CoarseGrainedExecutorBackend: Got assigned task 106
16/06/16 19:52:47 INFO Executor: Running task 6.0 in stage 1.0 (TID 106)
16/06/16 19:52:47 INFO CoarseGrainedExecutorBackend: Got assigned task 109
16/06/16 19:52:47 INFO CoarseGrainedExecutorBackend: Got assigned task 112
16/06/16 19:52:47 INFO Executor: Running task 9.0 in stage 1.0 (TID 109)
16/06/16 19:52:47 INFO Executor: Running task 12.0 in stage 1.0 (TID 112)
16/06/16 19:52:47 INFO CoarseGrainedExecutorBackend: Got assigned task 115
16/06/16 19:52:47 INFO Executor: Running task 15.0 in stage 1.0 (TID 115)
16/06/16 19:52:47 INFO CoarseGrainedExecutorBackend: Got assigned task 118
16/06/16 19:52:47 INFO Executor: Running task 18.0 in stage 1.0 (TID 118)
16/06/16 19:52:47 INFO CoarseGrainedExecutorBackend: Got assigned task 121
16/06/16 19:52:47 INFO Executor: Running task 21.0 in stage 1.0 (TID 121)
16/06/16 19:52:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 350.7 KB)
16/06/16 19:52:47 INFO TorrentBroadcast: Reading broadcast variable 2 took 37 ms
16/06/16 19:52:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.9 KB, free 356.5 KB)
16/06/16 19:52:47 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:7099971+2366657
16/06/16 19:52:47 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:49699797+2366657
16/06/16 19:52:47 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:42599826+2366657
16/06/16 19:52:47 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:35499855+2366657
16/06/16 19:52:47 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:28399884+2366657
16/06/16 19:52:47 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:21299913+2366657
16/06/16 19:52:47 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:14199942+2366657
16/06/16 19:52:47 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:0+2366657
16/06/16 19:52:56 INFO PythonRunner: Times: total = 8515, boot = -232, init = 255, finish = 8492
16/06/16 19:52:56 INFO Executor: Finished task 15.0 in stage 1.0 (TID 115). 2297 bytes result sent to driver
16/06/16 19:52:56 INFO CoarseGrainedExecutorBackend: Got assigned task 124
16/06/16 19:52:56 INFO Executor: Running task 24.0 in stage 1.0 (TID 124)
16/06/16 19:52:56 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:56799768+2366657
16/06/16 19:52:56 INFO PythonRunner: Times: total = 8581, boot = -2754, init = 2790, finish = 8545
16/06/16 19:52:56 INFO Executor: Finished task 21.0 in stage 1.0 (TID 121). 2234 bytes result sent to driver
16/06/16 19:52:56 INFO CoarseGrainedExecutorBackend: Got assigned task 125
16/06/16 19:52:56 INFO Executor: Running task 25.0 in stage 1.0 (TID 125)
16/06/16 19:52:56 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:59166425+2366657
16/06/16 19:52:56 INFO PythonRunner: Times: total = 8806, boot = -2286, init = 2364, finish = 8728
16/06/16 19:52:56 INFO Executor: Finished task 3.0 in stage 1.0 (TID 103). 2340 bytes result sent to driver
16/06/16 19:52:56 INFO CoarseGrainedExecutorBackend: Got assigned task 127
16/06/16 19:52:56 INFO Executor: Running task 27.0 in stage 1.0 (TID 127)
16/06/16 19:52:56 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:63899739+2366657
16/06/16 19:52:56 INFO PythonRunner: Times: total = 8859, boot = -2273, init = 2374, finish = 8758
16/06/16 19:52:56 INFO Executor: Finished task 12.0 in stage 1.0 (TID 112). 2254 bytes result sent to driver
16/06/16 19:52:56 INFO CoarseGrainedExecutorBackend: Got assigned task 128
16/06/16 19:52:56 INFO Executor: Running task 28.0 in stage 1.0 (TID 128)
16/06/16 19:52:56 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:66266396+2366657
16/06/16 19:52:56 INFO PythonRunner: Times: total = 9030, boot = -2123, init = 2318, finish = 8835
16/06/16 19:52:56 INFO Executor: Finished task 6.0 in stage 1.0 (TID 106). 2282 bytes result sent to driver
16/06/16 19:52:56 INFO CoarseGrainedExecutorBackend: Got assigned task 130
16/06/16 19:52:56 INFO Executor: Running task 30.0 in stage 1.0 (TID 130)
16/06/16 19:52:56 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:70999710+2366657
16/06/16 19:52:56 INFO PythonRunner: Times: total = 9189, boot = -1678, init = 1769, finish = 9098
16/06/16 19:52:56 INFO Executor: Finished task 18.0 in stage 1.0 (TID 118). 2315 bytes result sent to driver
16/06/16 19:52:56 INFO CoarseGrainedExecutorBackend: Got assigned task 135
16/06/16 19:52:56 INFO Executor: Running task 35.0 in stage 1.0 (TID 135)
16/06/16 19:52:56 INFO PythonRunner: Times: total = 9198, boot = -1924, init = 2146, finish = 8976
16/06/16 19:52:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 100). 2280 bytes result sent to driver
16/06/16 19:52:56 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:82832995+2366657
16/06/16 19:52:56 INFO CoarseGrainedExecutorBackend: Got assigned task 136
16/06/16 19:52:56 INFO Executor: Running task 36.0 in stage 1.0 (TID 136)
16/06/16 19:52:56 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:85199652+2366657
16/06/16 19:52:57 INFO PythonRunner: Times: total = 9610, boot = -1484, init = 1526, finish = 9568
16/06/16 19:52:57 INFO Executor: Finished task 9.0 in stage 1.0 (TID 109). 2325 bytes result sent to driver
16/06/16 19:52:57 INFO CoarseGrainedExecutorBackend: Got assigned task 141
16/06/16 19:52:57 INFO Executor: Running task 41.0 in stage 1.0 (TID 141)
16/06/16 19:52:57 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:97032937+2366657
16/06/16 19:53:05 INFO PythonRunner: Times: total = 9310, boot = 5, init = 25, finish = 9280
16/06/16 19:53:05 INFO Executor: Finished task 24.0 in stage 1.0 (TID 124). 2315 bytes result sent to driver
16/06/16 19:53:05 INFO CoarseGrainedExecutorBackend: Got assigned task 148
16/06/16 19:53:05 INFO Executor: Running task 48.0 in stage 1.0 (TID 148)
16/06/16 19:53:05 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:113599536+2366657
16/06/16 19:53:05 INFO PythonRunner: Times: total = 9710, boot = 17, init = 8, finish = 9685
16/06/16 19:53:05 INFO Executor: Finished task 25.0 in stage 1.0 (TID 125). 2276 bytes result sent to driver
16/06/16 19:53:05 INFO CoarseGrainedExecutorBackend: Got assigned task 150
16/06/16 19:53:05 INFO Executor: Running task 50.0 in stage 1.0 (TID 150)
16/06/16 19:53:05 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:118332850+2366657
16/06/16 19:53:06 INFO PythonRunner: Times: total = 9379, boot = 27, init = 104, finish = 9248
16/06/16 19:53:06 INFO Executor: Finished task 36.0 in stage 1.0 (TID 136). 2292 bytes result sent to driver
16/06/16 19:53:06 INFO CoarseGrainedExecutorBackend: Got assigned task 155
16/06/16 19:53:06 INFO Executor: Running task 55.0 in stage 1.0 (TID 155)
16/06/16 19:53:06 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:130166135+2366657
16/06/16 19:53:06 INFO PythonRunner: Times: total = 9920, boot = 27, init = 0, finish = 9893
16/06/16 19:53:06 INFO Executor: Finished task 27.0 in stage 1.0 (TID 127). 2297 bytes result sent to driver
16/06/16 19:53:06 INFO CoarseGrainedExecutorBackend: Got assigned task 158
16/06/16 19:53:06 INFO Executor: Running task 58.0 in stage 1.0 (TID 158)
16/06/16 19:53:06 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:137266106+2366657
16/06/16 19:53:06 INFO PythonRunner: Times: total = 9998, boot = -13, init = 104, finish = 9907
16/06/16 19:53:06 INFO Executor: Finished task 28.0 in stage 1.0 (TID 128). 2325 bytes result sent to driver
16/06/16 19:53:06 INFO PythonRunner: Times: total = 9802, boot = 32, init = 0, finish = 9770
16/06/16 19:53:06 INFO Executor: Finished task 30.0 in stage 1.0 (TID 130). 2247 bytes result sent to driver
16/06/16 19:53:06 INFO CoarseGrainedExecutorBackend: Got assigned task 159
16/06/16 19:53:06 INFO Executor: Running task 59.0 in stage 1.0 (TID 159)
16/06/16 19:53:06 INFO CoarseGrainedExecutorBackend: Got assigned task 160
16/06/16 19:53:06 INFO Executor: Running task 60.0 in stage 1.0 (TID 160)
16/06/16 19:53:06 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:141999420+2366657
16/06/16 19:53:06 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:139632763+2366657
16/06/16 19:53:06 INFO PythonRunner: Times: total = 10025, boot = 69, init = 1, finish = 9955
16/06/16 19:53:06 INFO Executor: Finished task 35.0 in stage 1.0 (TID 135). 2287 bytes result sent to driver
16/06/16 19:53:06 INFO PythonRunner: Times: total = 9598, boot = 32, init = 34, finish = 9532
16/06/16 19:53:06 INFO Executor: Finished task 41.0 in stage 1.0 (TID 141). 2285 bytes result sent to driver
16/06/16 19:53:06 INFO CoarseGrainedExecutorBackend: Got assigned task 164
16/06/16 19:53:06 INFO Executor: Running task 64.0 in stage 1.0 (TID 164)
16/06/16 19:53:06 INFO CoarseGrainedExecutorBackend: Got assigned task 166
16/06/16 19:53:06 INFO Executor: Running task 66.0 in stage 1.0 (TID 166)
16/06/16 19:53:06 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:156199362+2366657
16/06/16 19:53:06 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:151466048+2366657
16/06/16 19:53:14 INFO PythonRunner: Times: total = 8826, boot = 11, init = 15, finish = 8800
16/06/16 19:53:14 INFO Executor: Finished task 48.0 in stage 1.0 (TID 148). 2254 bytes result sent to driver
16/06/16 19:53:14 INFO CoarseGrainedExecutorBackend: Got assigned task 172
16/06/16 19:53:14 INFO Executor: Running task 72.0 in stage 1.0 (TID 172)
16/06/16 19:53:14 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:170399304+2366657
16/06/16 19:53:14 INFO PythonRunner: Times: total = 8976, boot = 12, init = 33, finish = 8931
16/06/16 19:53:14 INFO Executor: Finished task 50.0 in stage 1.0 (TID 150). 2315 bytes result sent to driver
16/06/16 19:53:14 INFO CoarseGrainedExecutorBackend: Got assigned task 175
16/06/16 19:53:14 INFO Executor: Running task 75.0 in stage 1.0 (TID 175)
16/06/16 19:53:14 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:177499275+2366657
16/06/16 19:53:15 INFO PythonRunner: Times: total = 8700, boot = 21, init = 7, finish = 8672
16/06/16 19:53:15 INFO Executor: Finished task 60.0 in stage 1.0 (TID 160). 2254 bytes result sent to driver
16/06/16 19:53:15 INFO CoarseGrainedExecutorBackend: Got assigned task 178
16/06/16 19:53:15 INFO Executor: Running task 78.0 in stage 1.0 (TID 178)
16/06/16 19:53:15 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:184599246+2366657
16/06/16 19:53:15 INFO PythonRunner: Times: total = 9239, boot = 40, init = 9, finish = 9190
16/06/16 19:53:15 INFO Executor: Finished task 55.0 in stage 1.0 (TID 155). 2340 bytes result sent to driver
16/06/16 19:53:15 INFO CoarseGrainedExecutorBackend: Got assigned task 181
16/06/16 19:53:15 INFO Executor: Running task 81.0 in stage 1.0 (TID 181)
16/06/16 19:53:15 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:191699217+2366657
16/06/16 19:53:15 INFO PythonRunner: Times: total = 9407, boot = -26, init = 51, finish = 9382
16/06/16 19:53:15 INFO Executor: Finished task 58.0 in stage 1.0 (TID 158). 2287 bytes result sent to driver
16/06/16 19:53:15 INFO CoarseGrainedExecutorBackend: Got assigned task 185
16/06/16 19:53:15 INFO Executor: Running task 85.0 in stage 1.0 (TID 185)
16/06/16 19:53:15 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:201165845+2366657
16/06/16 19:53:15 INFO PythonRunner: Times: total = 9507, boot = -50, init = 176, finish = 9381
16/06/16 19:53:15 INFO Executor: Finished task 59.0 in stage 1.0 (TID 159). 2282 bytes result sent to driver
16/06/16 19:53:15 INFO CoarseGrainedExecutorBackend: Got assigned task 186
16/06/16 19:53:15 INFO Executor: Running task 86.0 in stage 1.0 (TID 186)
16/06/16 19:53:15 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:203532502+2366657
16/06/16 19:53:16 INFO PythonRunner: Times: total = 9725, boot = 2, init = 23, finish = 9700
16/06/16 19:53:16 INFO Executor: Finished task 66.0 in stage 1.0 (TID 166). 2287 bytes result sent to driver
16/06/16 19:53:16 INFO PythonRunner: Times: total = 9743, boot = 12, init = 97, finish = 9634
16/06/16 19:53:16 INFO Executor: Finished task 64.0 in stage 1.0 (TID 164). 2315 bytes result sent to driver
16/06/16 19:53:16 INFO CoarseGrainedExecutorBackend: Got assigned task 191
16/06/16 19:53:16 INFO Executor: Running task 91.0 in stage 1.0 (TID 191)
16/06/16 19:53:16 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:215365787+2366657
16/06/16 19:53:16 INFO CoarseGrainedExecutorBackend: Got assigned task 192
16/06/16 19:53:16 INFO Executor: Running task 92.0 in stage 1.0 (TID 192)
16/06/16 19:53:16 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:217732444+2366657
16/06/16 19:53:23 INFO PythonRunner: Times: total = 9584, boot = 20, init = 19, finish = 9545
16/06/16 19:53:23 INFO Executor: Finished task 72.0 in stage 1.0 (TID 172). 2292 bytes result sent to driver
16/06/16 19:53:23 INFO CoarseGrainedExecutorBackend: Got assigned task 197
16/06/16 19:53:23 INFO Executor: Running task 97.0 in stage 1.0 (TID 197)
16/06/16 19:53:23 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:229565729+2366657
16/06/16 19:53:23 INFO PythonRunner: Times: total = 9072, boot = 43, init = 0, finish = 9029
16/06/16 19:53:23 INFO Executor: Finished task 75.0 in stage 1.0 (TID 175). 2377 bytes result sent to driver
16/06/16 19:53:23 INFO CoarseGrainedExecutorBackend: Got assigned task 199
16/06/16 19:53:23 INFO Executor: Running task 99.0 in stage 1.0 (TID 199)
16/06/16 19:53:23 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:234299043+2366711
16/06/16 19:53:24 INFO PythonRunner: Times: total = 8833, boot = 8, init = 6, finish = 8819
16/06/16 19:53:24 INFO Executor: Finished task 78.0 in stage 1.0 (TID 178). 2297 bytes result sent to driver
16/06/16 19:53:24 INFO PythonRunner: Times: total = 8488, boot = -25, init = 67, finish = 8446
16/06/16 19:53:24 INFO Executor: Finished task 86.0 in stage 1.0 (TID 186). 2287 bytes result sent to driver
16/06/16 19:53:24 INFO PythonRunner: Times: total = 9118, boot = 17, init = 70, finish = 9031
16/06/16 19:53:24 INFO Executor: Finished task 81.0 in stage 1.0 (TID 181). 2254 bytes result sent to driver
16/06/16 19:53:24 INFO PythonRunner: Times: total = 8924, boot = 37, init = 22, finish = 8865
16/06/16 19:53:24 INFO Executor: Finished task 85.0 in stage 1.0 (TID 185). 2276 bytes result sent to driver
16/06/16 19:53:25 INFO PythonRunner: Times: total = 8421, boot = 33, init = 25, finish = 8363
16/06/16 19:53:25 INFO Executor: Finished task 92.0 in stage 1.0 (TID 192). 2292 bytes result sent to driver
16/06/16 19:53:25 INFO PythonRunner: Times: total = 8464, boot = 20, init = 49, finish = 8395
16/06/16 19:53:25 INFO Executor: Finished task 91.0 in stage 1.0 (TID 191). 2249 bytes result sent to driver
16/06/16 19:53:26 INFO PythonRunner: Times: total = 2052, boot = -11, init = 58, finish = 2005
16/06/16 19:53:26 INFO Executor: Finished task 99.0 in stage 1.0 (TID 199). 2290 bytes result sent to driver
16/06/16 19:53:26 INFO PythonRunner: Times: total = 2211, boot = 76, init = 0, finish = 2135
16/06/16 19:53:26 INFO Executor: Finished task 97.0 in stage 1.0 (TID 197). 2343 bytes result sent to driver
16/06/16 19:53:26 INFO CoarseGrainedExecutorBackend: Got assigned task 201
16/06/16 19:53:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 201)
16/06/16 19:53:26 INFO CoarseGrainedExecutorBackend: Got assigned task 204
16/06/16 19:53:26 INFO Executor: Running task 4.0 in stage 2.0 (TID 204)
16/06/16 19:53:26 INFO CoarseGrainedExecutorBackend: Got assigned task 207
16/06/16 19:53:26 INFO CoarseGrainedExecutorBackend: Got assigned task 210
16/06/16 19:53:26 INFO Executor: Running task 7.0 in stage 2.0 (TID 207)
16/06/16 19:53:26 INFO CoarseGrainedExecutorBackend: Got assigned task 213
16/06/16 19:53:26 INFO Executor: Running task 10.0 in stage 2.0 (TID 210)
16/06/16 19:53:26 INFO CoarseGrainedExecutorBackend: Got assigned task 216
16/06/16 19:53:26 INFO Executor: Running task 13.0 in stage 2.0 (TID 213)
16/06/16 19:53:26 INFO Executor: Running task 16.0 in stage 2.0 (TID 216)
16/06/16 19:53:26 INFO CoarseGrainedExecutorBackend: Got assigned task 219
16/06/16 19:53:26 INFO Executor: Running task 19.0 in stage 2.0 (TID 219)
16/06/16 19:53:26 INFO CoarseGrainedExecutorBackend: Got assigned task 222
16/06/16 19:53:26 INFO TorrentBroadcast: Started reading broadcast variable 3
16/06/16 19:53:26 INFO Executor: Running task 22.0 in stage 2.0 (TID 222)
16/06/16 19:53:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.2 KB, free 361.7 KB)
16/06/16 19:53:26 INFO TorrentBroadcast: Reading broadcast variable 3 took 47 ms
16/06/16 19:53:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.0 KB, free 369.7 KB)
16/06/16 19:53:26 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:44966483+2366657
16/06/16 19:53:26 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:16566599+2366657
16/06/16 19:53:26 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:30766541+2366657
16/06/16 19:53:26 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:2366657+2366657
16/06/16 19:53:26 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:37866512+2366657
16/06/16 19:53:26 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:52066454+2366657
16/06/16 19:53:26 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:23666570+2366657
16/06/16 19:53:26 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:9466628+2366657
16/06/16 19:53:40 INFO PythonRunner: Times: total = 14032, boot = -2303, init = 2325, finish = 14010
16/06/16 19:53:40 INFO PythonRunner: Times: total = 14117, boot = -329, init = 409, finish = 14037
16/06/16 19:53:40 INFO PythonRunner: Times: total = 14412, boot = -1822, init = 2401, finish = 13833
16/06/16 19:53:40 INFO Executor: Finished task 7.0 in stage 2.0 (TID 207). 2417 bytes result sent to driver
16/06/16 19:53:40 INFO CoarseGrainedExecutorBackend: Got assigned task 227
16/06/16 19:53:40 INFO Executor: Running task 27.0 in stage 2.0 (TID 227)
16/06/16 19:53:40 INFO Executor: Finished task 19.0 in stage 2.0 (TID 219). 2417 bytes result sent to driver
16/06/16 19:53:40 INFO CoarseGrainedExecutorBackend: Got assigned task 228
16/06/16 19:53:40 INFO Executor: Running task 28.0 in stage 2.0 (TID 228)
16/06/16 19:53:40 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:66266396+2366657
16/06/16 19:53:40 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:63899739+2366657
16/06/16 19:53:41 INFO PythonRunner: Times: total = 14587, boot = -347, init = 563, finish = 14371
16/06/16 19:53:41 INFO PythonRunner: Times: total = 14619, boot = -1812, init = 2327, finish = 14104
16/06/16 19:53:41 INFO PythonRunner: Times: total = 14692, boot = -1339, init = 1371, finish = 14660
16/06/16 19:53:41 INFO PythonRunner: Times: total = 14841, boot = -1675, init = 1709, finish = 14807
16/06/16 19:53:41 INFO Executor: Finished task 13.0 in stage 2.0 (TID 213). 2417 bytes result sent to driver
16/06/16 19:53:41 INFO CoarseGrainedExecutorBackend: Got assigned task 236
16/06/16 19:53:41 INFO Executor: Running task 36.0 in stage 2.0 (TID 236)
16/06/16 19:53:41 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:85199652+2366657
16/06/16 19:53:41 INFO Executor: Finished task 10.0 in stage 2.0 (TID 210). 2417 bytes result sent to driver
16/06/16 19:53:41 INFO CoarseGrainedExecutorBackend: Got assigned task 238
16/06/16 19:53:41 INFO Executor: Running task 38.0 in stage 2.0 (TID 238)
16/06/16 19:53:41 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:89932966+2366657
16/06/16 19:53:41 INFO Executor: Finished task 1.0 in stage 2.0 (TID 201). 2417 bytes result sent to driver
16/06/16 19:53:41 INFO CoarseGrainedExecutorBackend: Got assigned task 239
16/06/16 19:53:41 INFO Executor: Running task 39.0 in stage 2.0 (TID 239)
16/06/16 19:53:41 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:92299623+2366657
16/06/16 19:53:41 INFO Executor: Finished task 22.0 in stage 2.0 (TID 222). 2417 bytes result sent to driver
16/06/16 19:53:41 INFO CoarseGrainedExecutorBackend: Got assigned task 240
16/06/16 19:53:41 INFO Executor: Running task 40.0 in stage 2.0 (TID 240)
16/06/16 19:53:41 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:94666280+2366657
16/06/16 19:53:41 INFO Executor: Finished task 16.0 in stage 2.0 (TID 216). 2417 bytes result sent to driver
16/06/16 19:53:41 INFO CoarseGrainedExecutorBackend: Got assigned task 241
16/06/16 19:53:41 INFO Executor: Running task 41.0 in stage 2.0 (TID 241)
16/06/16 19:53:41 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:97032937+2366657
16/06/16 19:53:42 INFO PythonRunner: Times: total = 16152, boot = -1310, init = 1427, finish = 16035
16/06/16 19:53:43 INFO Executor: Finished task 4.0 in stage 2.0 (TID 204). 2417 bytes result sent to driver
16/06/16 19:53:43 INFO CoarseGrainedExecutorBackend: Got assigned task 246
16/06/16 19:53:43 INFO Executor: Running task 46.0 in stage 2.0 (TID 246)
16/06/16 19:53:43 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:108866222+2366657
16/06/16 19:53:53 INFO PythonRunner: Times: total = 12998, boot = -354, init = 387, finish = 12965
16/06/16 19:53:53 INFO Executor: Finished task 28.0 in stage 2.0 (TID 228). 2417 bytes result sent to driver
16/06/16 19:53:53 INFO CoarseGrainedExecutorBackend: Got assigned task 248
16/06/16 19:53:53 INFO Executor: Running task 48.0 in stage 2.0 (TID 248)
16/06/16 19:53:54 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:113599536+2366657
16/06/16 19:53:55 INFO PythonRunner: Times: total = 13661, boot = -507, init = 604, finish = 13564
16/06/16 19:53:55 INFO PythonRunner: Times: total = 14325, boot = -242, init = 290, finish = 14277
16/06/16 19:53:55 INFO Executor: Finished task 36.0 in stage 2.0 (TID 236). 2417 bytes result sent to driver
16/06/16 19:53:55 INFO CoarseGrainedExecutorBackend: Got assigned task 258
16/06/16 19:53:55 INFO Executor: Running task 58.0 in stage 2.0 (TID 258)
16/06/16 19:53:55 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:137266106+2366657
16/06/16 19:53:55 INFO Executor: Finished task 27.0 in stage 2.0 (TID 227). 2417 bytes result sent to driver
16/06/16 19:53:55 INFO PythonRunner: Times: total = 13491, boot = -647, init = 662, finish = 13476
16/06/16 19:53:55 INFO CoarseGrainedExecutorBackend: Got assigned task 259
16/06/16 19:53:55 INFO Executor: Running task 59.0 in stage 2.0 (TID 259)
16/06/16 19:53:55 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:139632763+2366657
16/06/16 19:53:55 INFO PythonRunner: Times: total = 14036, boot = -568, init = 607, finish = 13997
16/06/16 19:53:55 INFO Executor: Finished task 41.0 in stage 2.0 (TID 241). 2417 bytes result sent to driver
16/06/16 19:53:55 INFO CoarseGrainedExecutorBackend: Got assigned task 263
16/06/16 19:53:55 INFO Executor: Running task 63.0 in stage 2.0 (TID 263)
16/06/16 19:53:55 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:149099391+2366657
16/06/16 19:53:55 INFO PythonRunner: Times: total = 14222, boot = -739, init = 844, finish = 14117
16/06/16 19:53:55 INFO Executor: Finished task 38.0 in stage 2.0 (TID 238). 2417 bytes result sent to driver
16/06/16 19:53:56 INFO CoarseGrainedExecutorBackend: Got assigned task 264
16/06/16 19:53:56 INFO Executor: Running task 64.0 in stage 2.0 (TID 264)
16/06/16 19:53:56 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:151466048+2366657
16/06/16 19:53:56 INFO PythonRunner: Times: total = 14477, boot = -681, init = 727, finish = 14431
16/06/16 19:53:56 INFO Executor: Finished task 39.0 in stage 2.0 (TID 239). 2417 bytes result sent to driver
16/06/16 19:53:56 INFO CoarseGrainedExecutorBackend: Got assigned task 267
16/06/16 19:53:56 INFO Executor: Running task 67.0 in stage 2.0 (TID 267)
16/06/16 19:53:56 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:158566019+2366657
16/06/16 19:53:56 INFO Executor: Finished task 40.0 in stage 2.0 (TID 240). 2417 bytes result sent to driver
16/06/16 19:53:56 INFO CoarseGrainedExecutorBackend: Got assigned task 268
16/06/16 19:53:56 INFO Executor: Running task 68.0 in stage 2.0 (TID 268)
16/06/16 19:53:56 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:160932676+2366657
16/06/16 19:53:57 INFO PythonRunner: Times: total = 14501, boot = -657, init = 743, finish = 14415
16/06/16 19:53:57 INFO Executor: Finished task 46.0 in stage 2.0 (TID 246). 2417 bytes result sent to driver
16/06/16 19:53:58 INFO CoarseGrainedExecutorBackend: Got assigned task 271
16/06/16 19:53:58 INFO Executor: Running task 71.0 in stage 2.0 (TID 271)
16/06/16 19:53:58 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:168032647+2366657
16/06/16 19:54:07 INFO PythonRunner: Times: total = 13885, boot = -146, init = 173, finish = 13858
16/06/16 19:54:08 INFO Executor: Finished task 48.0 in stage 2.0 (TID 248). 2417 bytes result sent to driver
16/06/16 19:54:08 INFO CoarseGrainedExecutorBackend: Got assigned task 272
16/06/16 19:54:08 INFO Executor: Running task 72.0 in stage 2.0 (TID 272)
16/06/16 19:54:08 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:170399304+2366657
16/06/16 19:54:08 INFO PythonRunner: Times: total = 13384, boot = -309, init = 356, finish = 13337
16/06/16 19:54:08 INFO Executor: Finished task 58.0 in stage 2.0 (TID 258). 2417 bytes result sent to driver
16/06/16 19:54:08 INFO CoarseGrainedExecutorBackend: Got assigned task 275
16/06/16 19:54:08 INFO Executor: Running task 75.0 in stage 2.0 (TID 275)
16/06/16 19:54:08 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:177499275+2366657
16/06/16 19:54:09 INFO PythonRunner: Times: total = 13729, boot = -247, init = 266, finish = 13710
16/06/16 19:54:09 INFO PythonRunner: Times: total = 13558, boot = -385, init = 408, finish = 13535
16/06/16 19:54:09 INFO Executor: Finished task 59.0 in stage 2.0 (TID 259). 2417 bytes result sent to driver
16/06/16 19:54:09 INFO CoarseGrainedExecutorBackend: Got assigned task 279
16/06/16 19:54:09 INFO Executor: Running task 79.0 in stage 2.0 (TID 279)
16/06/16 19:54:09 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:186965903+2366657
16/06/16 19:54:09 INFO Executor: Finished task 63.0 in stage 2.0 (TID 263). 2417 bytes result sent to driver
16/06/16 19:54:09 INFO CoarseGrainedExecutorBackend: Got assigned task 282
16/06/16 19:54:09 INFO Executor: Running task 82.0 in stage 2.0 (TID 282)
16/06/16 19:54:09 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:194065874+2366657
16/06/16 19:54:10 INFO PythonRunner: Times: total = 13857, boot = -467, init = 558, finish = 13766
16/06/16 19:54:10 INFO PythonRunner: Times: total = 13741, boot = -342, init = 371, finish = 13712
16/06/16 19:54:10 INFO Executor: Finished task 67.0 in stage 2.0 (TID 267). 2417 bytes result sent to driver
16/06/16 19:54:10 INFO CoarseGrainedExecutorBackend: Got assigned task 289
16/06/16 19:54:10 INFO Executor: Running task 89.0 in stage 2.0 (TID 289)
16/06/16 19:54:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:210632473+2366657
16/06/16 19:54:10 INFO Executor: Finished task 68.0 in stage 2.0 (TID 268). 2417 bytes result sent to driver
16/06/16 19:54:10 INFO CoarseGrainedExecutorBackend: Got assigned task 290
16/06/16 19:54:10 INFO Executor: Running task 90.0 in stage 2.0 (TID 290)
16/06/16 19:54:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:212999130+2366657
16/06/16 19:54:11 INFO PythonRunner: Times: total = 15310, boot = -416, init = 452, finish = 15274
16/06/16 19:54:11 INFO Executor: Finished task 64.0 in stage 2.0 (TID 264). 2417 bytes result sent to driver
16/06/16 19:54:11 INFO CoarseGrainedExecutorBackend: Got assigned task 292
16/06/16 19:54:11 INFO Executor: Running task 92.0 in stage 2.0 (TID 292)
16/06/16 19:54:11 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:217732444+2366657
16/06/16 19:54:12 INFO PythonRunner: Times: total = 14402, boot = -215, init = 252, finish = 14365
16/06/16 19:54:12 INFO Executor: Finished task 71.0 in stage 2.0 (TID 271). 2417 bytes result sent to driver
16/06/16 19:54:12 INFO CoarseGrainedExecutorBackend: Got assigned task 294
16/06/16 19:54:12 INFO Executor: Running task 94.0 in stage 2.0 (TID 294)
16/06/16 19:54:12 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:222465758+2366657
16/06/16 19:54:21 INFO PythonRunner: Times: total = 13654, boot = -186, init = 202, finish = 13638
16/06/16 19:54:21 INFO Executor: Finished task 72.0 in stage 2.0 (TID 272). 2417 bytes result sent to driver
16/06/16 19:54:22 INFO CoarseGrainedExecutorBackend: Got assigned task 296
16/06/16 19:54:22 INFO Executor: Running task 96.0 in stage 2.0 (TID 296)
16/06/16 19:54:22 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:227199072+2366657
16/06/16 19:54:22 INFO PythonRunner: Times: total = 13799, boot = -178, init = 217, finish = 13760
16/06/16 19:54:23 INFO Executor: Finished task 75.0 in stage 2.0 (TID 275). 2417 bytes result sent to driver
16/06/16 19:54:23 INFO CoarseGrainedExecutorBackend: Got assigned task 299
16/06/16 19:54:23 INFO Executor: Running task 99.0 in stage 2.0 (TID 299)
16/06/16 19:54:23 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:234299043+2366711
16/06/16 19:54:23 INFO PythonRunner: Times: total = 13052, boot = -412, init = 480, finish = 12984
16/06/16 19:54:23 INFO PythonRunner: Times: total = 13007, boot = -457, init = 495, finish = 12969
16/06/16 19:54:24 INFO Executor: Finished task 89.0 in stage 2.0 (TID 289). 2417 bytes result sent to driver
16/06/16 19:54:24 INFO Executor: Finished task 90.0 in stage 2.0 (TID 290). 2417 bytes result sent to driver
16/06/16 19:54:24 INFO PythonRunner: Times: total = 14411, boot = -305, init = 336, finish = 14380
16/06/16 19:54:24 INFO Executor: Finished task 82.0 in stage 2.0 (TID 282). 2417 bytes result sent to driver
16/06/16 19:54:24 INFO PythonRunner: Times: total = 12760, boot = -196, init = 247, finish = 12709
16/06/16 19:54:24 INFO Executor: Finished task 92.0 in stage 2.0 (TID 292). 2417 bytes result sent to driver
16/06/16 19:54:24 INFO PythonRunner: Times: total = 15079, boot = -309, init = 372, finish = 15016
16/06/16 19:54:24 INFO Executor: Finished task 79.0 in stage 2.0 (TID 279). 2417 bytes result sent to driver
16/06/16 19:54:24 INFO PythonRunner: Times: total = 12179, boot = -187, init = 213, finish = 12153
16/06/16 19:54:24 INFO Executor: Finished task 94.0 in stage 2.0 (TID 294). 2417 bytes result sent to driver
16/06/16 19:54:26 INFO PythonRunner: Times: total = 4475, boot = -126, init = 152, finish = 4449
16/06/16 19:54:26 INFO Executor: Finished task 96.0 in stage 2.0 (TID 296). 2417 bytes result sent to driver
16/06/16 19:54:26 INFO PythonRunner: Times: total = 3590, boot = -186, init = 214, finish = 3562
16/06/16 19:54:26 INFO Executor: Finished task 99.0 in stage 2.0 (TID 299). 2417 bytes result sent to driver
16/06/16 19:54:26 INFO CoarseGrainedExecutorBackend: Got assigned task 301
16/06/16 19:54:26 INFO CoarseGrainedExecutorBackend: Got assigned task 304
16/06/16 19:54:26 INFO Executor: Running task 4.0 in stage 3.0 (TID 304)
16/06/16 19:54:26 INFO CoarseGrainedExecutorBackend: Got assigned task 307
16/06/16 19:54:26 INFO CoarseGrainedExecutorBackend: Got assigned task 310
16/06/16 19:54:26 INFO Executor: Running task 10.0 in stage 3.0 (TID 310)
16/06/16 19:54:26 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
16/06/16 19:54:26 INFO Executor: Running task 7.0 in stage 3.0 (TID 307)
16/06/16 19:54:26 INFO TorrentBroadcast: Started reading broadcast variable 4
16/06/16 19:54:26 INFO Executor: Running task 1.0 in stage 3.0 (TID 301)
16/06/16 19:54:26 INFO CoarseGrainedExecutorBackend: Got assigned task 313
16/06/16 19:54:26 INFO CoarseGrainedExecutorBackend: Got assigned task 316
16/06/16 19:54:26 INFO CoarseGrainedExecutorBackend: Got assigned task 319
16/06/16 19:54:26 INFO CoarseGrainedExecutorBackend: Got assigned task 322
16/06/16 19:54:26 INFO Executor: Running task 13.0 in stage 3.0 (TID 313)
16/06/16 19:54:26 INFO Executor: Running task 16.0 in stage 3.0 (TID 316)
16/06/16 19:54:26 INFO Executor: Running task 19.0 in stage 3.0 (TID 319)
16/06/16 19:54:26 INFO Executor: Running task 22.0 in stage 3.0 (TID 322)
16/06/16 19:54:26 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.2 KB, free 396.9 KB)
16/06/16 19:54:26 INFO TorrentBroadcast: Reading broadcast variable 4 took 23 ms
16/06/16 19:54:26 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 75.0 KB, free 471.9 KB)
16/06/16 19:54:26 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
16/06/16 19:54:26 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@192.168.1.12:54127)
16/06/16 19:54:26 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
16/06/16 19:54:26 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
16/06/16 19:54:26 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
16/06/16 19:54:26 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
16/06/16 19:54:26 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
16/06/16 19:54:26 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
16/06/16 19:54:26 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
16/06/16 19:54:26 INFO MapOutputTrackerWorker: Got the output locations
16/06/16 19:54:26 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:26 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:26 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:26 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:26 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:26 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:26 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:26 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:27 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 71 ms
16/06/16 19:54:27 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 76 ms
16/06/16 19:54:27 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 70 ms
16/06/16 19:54:27 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 80 ms
16/06/16 19:54:27 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 85 ms
16/06/16 19:54:27 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 81 ms
16/06/16 19:54:27 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 95 ms
16/06/16 19:54:27 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 96 ms
16/06/16 19:54:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:38 INFO PythonRunner: Times: total = 11413, boot = -2214, init = 2283, finish = 11344
16/06/16 19:54:38 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000022_322' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000022
16/06/16 19:54:38 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000022_322: Committed
16/06/16 19:54:38 INFO Executor: Finished task 22.0 in stage 3.0 (TID 322). 2147 bytes result sent to driver
16/06/16 19:54:38 INFO CoarseGrainedExecutorBackend: Got assigned task 324
16/06/16 19:54:38 INFO Executor: Running task 24.0 in stage 3.0 (TID 324)
16/06/16 19:54:38 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:38 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 32 ms
16/06/16 19:54:40 INFO PythonRunner: Times: total = 13247, boot = -2346, init = 2515, finish = 13078
16/06/16 19:54:40 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000013_313' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000013
16/06/16 19:54:40 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000013_313: Committed
16/06/16 19:54:40 INFO Executor: Finished task 13.0 in stage 3.0 (TID 313). 2147 bytes result sent to driver
16/06/16 19:54:40 INFO CoarseGrainedExecutorBackend: Got assigned task 327
16/06/16 19:54:40 INFO Executor: Running task 27.0 in stage 3.0 (TID 327)
16/06/16 19:54:40 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:40 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 24 ms
16/06/16 19:54:40 INFO PythonRunner: Times: total = 13919, boot = -411, init = 562, finish = 13768
16/06/16 19:54:40 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000016_316' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000016
16/06/16 19:54:40 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000016_316: Committed
16/06/16 19:54:40 INFO Executor: Finished task 16.0 in stage 3.0 (TID 316). 2147 bytes result sent to driver
16/06/16 19:54:40 INFO CoarseGrainedExecutorBackend: Got assigned task 330
16/06/16 19:54:40 INFO Executor: Running task 30.0 in stage 3.0 (TID 330)
16/06/16 19:54:41 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:41 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 8 ms
16/06/16 19:54:41 INFO PythonRunner: Times: total = 14615, boot = -564, init = 729, finish = 14450
16/06/16 19:54:41 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000007_307' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000007
16/06/16 19:54:41 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000007_307: Committed
16/06/16 19:54:41 INFO Executor: Finished task 7.0 in stage 3.0 (TID 307). 2147 bytes result sent to driver
16/06/16 19:54:41 INFO CoarseGrainedExecutorBackend: Got assigned task 331
16/06/16 19:54:41 INFO Executor: Running task 31.0 in stage 3.0 (TID 331)
16/06/16 19:54:41 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:41 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 16 ms
16/06/16 19:54:43 INFO PythonRunner: Times: total = 16308, boot = -3068, init = 3139, finish = 16237
16/06/16 19:54:43 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000010_310' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000010
16/06/16 19:54:43 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000010_310: Committed
16/06/16 19:54:43 INFO Executor: Finished task 10.0 in stage 3.0 (TID 310). 2147 bytes result sent to driver
16/06/16 19:54:43 INFO CoarseGrainedExecutorBackend: Got assigned task 335
16/06/16 19:54:43 INFO Executor: Running task 35.0 in stage 3.0 (TID 335)
16/06/16 19:54:43 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:43 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 33 ms
16/06/16 19:54:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:45 INFO PythonRunner: Times: total = 18817, boot = -2801, init = 2985, finish = 18633
16/06/16 19:54:45 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000001_301' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000001
16/06/16 19:54:45 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000001_301: Committed
16/06/16 19:54:45 INFO Executor: Finished task 1.0 in stage 3.0 (TID 301). 2147 bytes result sent to driver
16/06/16 19:54:45 INFO CoarseGrainedExecutorBackend: Got assigned task 339
16/06/16 19:54:45 INFO Executor: Running task 39.0 in stage 3.0 (TID 339)
16/06/16 19:54:45 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:45 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 32 ms
16/06/16 19:54:46 INFO PythonRunner: Times: total = 19383, boot = -3100, init = 3177, finish = 19306
16/06/16 19:54:46 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000004_304' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000004
16/06/16 19:54:46 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000004_304: Committed
16/06/16 19:54:46 INFO Executor: Finished task 4.0 in stage 3.0 (TID 304). 2147 bytes result sent to driver
16/06/16 19:54:46 INFO CoarseGrainedExecutorBackend: Got assigned task 340
16/06/16 19:54:46 INFO Executor: Running task 40.0 in stage 3.0 (TID 340)
16/06/16 19:54:46 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:46 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 23 ms
16/06/16 19:54:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:49 INFO PythonRunner: Times: total = 22245, boot = -2639, init = 2690, finish = 22194
16/06/16 19:54:49 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000019_319' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000019
16/06/16 19:54:49 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000019_319: Committed
16/06/16 19:54:49 INFO Executor: Finished task 19.0 in stage 3.0 (TID 319). 2147 bytes result sent to driver
16/06/16 19:54:49 INFO CoarseGrainedExecutorBackend: Got assigned task 346
16/06/16 19:54:49 INFO Executor: Running task 46.0 in stage 3.0 (TID 346)
16/06/16 19:54:49 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:49 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 39 ms
16/06/16 19:54:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:52 INFO PythonRunner: Times: total = 11201, boot = 35, init = 0, finish = 11166
16/06/16 19:54:52 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000031_331' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000031
16/06/16 19:54:52 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000031_331: Committed
16/06/16 19:54:52 INFO Executor: Finished task 31.0 in stage 3.0 (TID 331). 2147 bytes result sent to driver
16/06/16 19:54:52 INFO CoarseGrainedExecutorBackend: Got assigned task 348
16/06/16 19:54:52 INFO Executor: Running task 48.0 in stage 3.0 (TID 348)
16/06/16 19:54:52 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:52 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 2 ms
16/06/16 19:54:53 INFO PythonRunner: Times: total = 14721, boot = -49, init = 97, finish = 14673
16/06/16 19:54:53 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000024_324' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000024
16/06/16 19:54:53 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000024_324: Committed
16/06/16 19:54:53 INFO Executor: Finished task 24.0 in stage 3.0 (TID 324). 2147 bytes result sent to driver
16/06/16 19:54:53 INFO CoarseGrainedExecutorBackend: Got assigned task 349
16/06/16 19:54:53 INFO Executor: Running task 49.0 in stage 3.0 (TID 349)
16/06/16 19:54:53 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:53 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 33 ms
16/06/16 19:54:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:55 INFO PythonRunner: Times: total = 14644, boot = 12, init = 12, finish = 14620
16/06/16 19:54:55 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000030_330' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000030
16/06/16 19:54:55 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000030_330: Committed
16/06/16 19:54:55 INFO Executor: Finished task 30.0 in stage 3.0 (TID 330). 2147 bytes result sent to driver
16/06/16 19:54:55 INFO CoarseGrainedExecutorBackend: Got assigned task 351
16/06/16 19:54:55 INFO Executor: Running task 51.0 in stage 3.0 (TID 351)
16/06/16 19:54:55 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:55 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 20 ms
16/06/16 19:54:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:54:58 INFO PythonRunner: Times: total = 12257, boot = 29, init = 33, finish = 12195
16/06/16 19:54:58 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000040_340' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000040
16/06/16 19:54:58 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000040_340: Committed
16/06/16 19:54:58 INFO Executor: Finished task 40.0 in stage 3.0 (TID 340). 2147 bytes result sent to driver
16/06/16 19:54:58 INFO CoarseGrainedExecutorBackend: Got assigned task 357
16/06/16 19:54:58 INFO Executor: Running task 57.0 in stage 3.0 (TID 357)
16/06/16 19:54:58 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:54:58 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 7 ms
16/06/16 19:55:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:01 INFO PythonRunner: Times: total = 17772, boot = 14, init = 36, finish = 17722
16/06/16 19:55:01 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000035_335' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000035
16/06/16 19:55:01 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000035_335: Committed
16/06/16 19:55:01 INFO Executor: Finished task 35.0 in stage 3.0 (TID 335). 2147 bytes result sent to driver
16/06/16 19:55:01 INFO CoarseGrainedExecutorBackend: Got assigned task 362
16/06/16 19:55:01 INFO Executor: Running task 62.0 in stage 3.0 (TID 362)
16/06/16 19:55:01 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:01 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 8 ms
16/06/16 19:55:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:04 INFO PythonRunner: Times: total = 15056, boot = 8, init = 23, finish = 15025
16/06/16 19:55:04 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000046_346' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000046
16/06/16 19:55:04 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000046_346: Committed
16/06/16 19:55:04 INFO Executor: Finished task 46.0 in stage 3.0 (TID 346). 2147 bytes result sent to driver
16/06/16 19:55:04 INFO CoarseGrainedExecutorBackend: Got assigned task 366
16/06/16 19:55:04 INFO Executor: Running task 66.0 in stage 3.0 (TID 366)
16/06/16 19:55:04 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:04 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 28 ms
16/06/16 19:55:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:05 INFO PythonRunner: Times: total = 19669, boot = -10, init = 55, finish = 19624
16/06/16 19:55:05 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000039_339' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000039
16/06/16 19:55:05 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000039_339: Committed
16/06/16 19:55:05 INFO Executor: Finished task 39.0 in stage 3.0 (TID 339). 2147 bytes result sent to driver
16/06/16 19:55:05 INFO CoarseGrainedExecutorBackend: Got assigned task 368
16/06/16 19:55:05 INFO Executor: Running task 68.0 in stage 3.0 (TID 368)
16/06/16 19:55:05 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:05 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 22 ms
16/06/16 19:55:06 INFO PythonRunner: Times: total = 13137, boot = 31, init = 23, finish = 13083
16/06/16 19:55:06 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000048_348' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000048
16/06/16 19:55:06 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000048_348: Committed
16/06/16 19:55:06 INFO Executor: Finished task 48.0 in stage 3.0 (TID 348). 2147 bytes result sent to driver
16/06/16 19:55:06 INFO CoarseGrainedExecutorBackend: Got assigned task 369
16/06/16 19:55:06 INFO Executor: Running task 69.0 in stage 3.0 (TID 369)
16/06/16 19:55:06 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:06 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 10 ms
16/06/16 19:55:06 INFO PythonRunner: Times: total = 26419, boot = -18, init = 76, finish = 26361
16/06/16 19:55:06 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000027_327' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000027
16/06/16 19:55:06 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000027_327: Committed
16/06/16 19:55:06 INFO Executor: Finished task 27.0 in stage 3.0 (TID 327). 2147 bytes result sent to driver
16/06/16 19:55:06 INFO CoarseGrainedExecutorBackend: Got assigned task 370
16/06/16 19:55:06 INFO Executor: Running task 70.0 in stage 3.0 (TID 370)
16/06/16 19:55:06 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:06 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 13 ms
16/06/16 19:55:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:08 INFO PythonRunner: Times: total = 14893, boot = -11, init = 54, finish = 14850
16/06/16 19:55:08 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000049_349' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000049
16/06/16 19:55:08 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000049_349: Committed
16/06/16 19:55:08 INFO Executor: Finished task 49.0 in stage 3.0 (TID 349). 2147 bytes result sent to driver
16/06/16 19:55:08 INFO CoarseGrainedExecutorBackend: Got assigned task 372
16/06/16 19:55:08 INFO Executor: Running task 72.0 in stage 3.0 (TID 372)
16/06/16 19:55:08 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:08 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 3 ms
16/06/16 19:55:10 INFO PythonRunner: Times: total = 14834, boot = 54, init = 0, finish = 14780
16/06/16 19:55:10 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000051_351' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000051
16/06/16 19:55:10 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000051_351: Committed
16/06/16 19:55:10 INFO Executor: Finished task 51.0 in stage 3.0 (TID 351). 2147 bytes result sent to driver
16/06/16 19:55:10 INFO CoarseGrainedExecutorBackend: Got assigned task 376
16/06/16 19:55:10 INFO Executor: Running task 76.0 in stage 3.0 (TID 376)
16/06/16 19:55:10 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:10 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 2 ms
16/06/16 19:55:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:14 INFO PythonRunner: Times: total = 12842, boot = 34, init = 0, finish = 12808
16/06/16 19:55:14 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000062_362' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000062
16/06/16 19:55:14 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000062_362: Committed
16/06/16 19:55:14 INFO Executor: Finished task 62.0 in stage 3.0 (TID 362). 2147 bytes result sent to driver
16/06/16 19:55:14 INFO CoarseGrainedExecutorBackend: Got assigned task 380
16/06/16 19:55:14 INFO Executor: Running task 80.0 in stage 3.0 (TID 380)
16/06/16 19:55:14 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:14 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 15 ms
16/06/16 19:55:14 INFO PythonRunner: Times: total = 10366, boot = -91, init = 119, finish = 10338
16/06/16 19:55:14 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000066_366' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000066
16/06/16 19:55:14 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000066_366: Committed
16/06/16 19:55:14 INFO Executor: Finished task 66.0 in stage 3.0 (TID 366). 2147 bytes result sent to driver
16/06/16 19:55:14 INFO CoarseGrainedExecutorBackend: Got assigned task 381
16/06/16 19:55:14 INFO Executor: Running task 81.0 in stage 3.0 (TID 381)
16/06/16 19:55:14 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:14 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 14 ms
16/06/16 19:55:15 INFO PythonRunner: Times: total = 16496, boot = 40, init = 0, finish = 16456
16/06/16 19:55:15 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000057_357' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000057
16/06/16 19:55:15 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000057_357: Committed
16/06/16 19:55:15 INFO Executor: Finished task 57.0 in stage 3.0 (TID 357). 2147 bytes result sent to driver
16/06/16 19:55:15 INFO CoarseGrainedExecutorBackend: Got assigned task 382
16/06/16 19:55:15 INFO Executor: Running task 82.0 in stage 3.0 (TID 382)
16/06/16 19:55:15 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:15 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 14 ms
16/06/16 19:55:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:20 INFO PythonRunner: Times: total = 14063, boot = 57, init = 1, finish = 14005
16/06/16 19:55:20 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000070_370' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000070
16/06/16 19:55:20 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000070_370: Committed
16/06/16 19:55:20 INFO Executor: Finished task 70.0 in stage 3.0 (TID 370). 2147 bytes result sent to driver
16/06/16 19:55:20 INFO CoarseGrainedExecutorBackend: Got assigned task 392
16/06/16 19:55:20 INFO Executor: Running task 92.0 in stage 3.0 (TID 392)
16/06/16 19:55:20 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:20 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 54 ms
16/06/16 19:55:22 INFO PythonRunner: Times: total = 16369, boot = 11, init = 25, finish = 16333
16/06/16 19:55:22 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000069_369' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000069
16/06/16 19:55:22 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000069_369: Committed
16/06/16 19:55:22 INFO Executor: Finished task 69.0 in stage 3.0 (TID 369). 2147 bytes result sent to driver
16/06/16 19:55:22 INFO CoarseGrainedExecutorBackend: Got assigned task 395
16/06/16 19:55:22 INFO Executor: Running task 95.0 in stage 3.0 (TID 395)
16/06/16 19:55:22 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:22 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 2 ms
16/06/16 19:55:24 INFO PythonRunner: Times: total = 16372, boot = -6, init = 40, finish = 16338
16/06/16 19:55:24 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000072_372' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000072
16/06/16 19:55:24 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000072_372: Committed
16/06/16 19:55:24 INFO Executor: Finished task 72.0 in stage 3.0 (TID 372). 2147 bytes result sent to driver
16/06/16 19:55:24 INFO CoarseGrainedExecutorBackend: Got assigned task 398
16/06/16 19:55:24 INFO Executor: Running task 98.0 in stage 3.0 (TID 398)
16/06/16 19:55:24 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:24 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 1 ms
16/06/16 19:55:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:26 INFO PythonRunner: Times: total = 20732, boot = 2, init = 32, finish = 20698
16/06/16 19:55:26 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000068_368' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000068
16/06/16 19:55:26 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000068_368: Committed
16/06/16 19:55:26 INFO Executor: Finished task 68.0 in stage 3.0 (TID 368). 2147 bytes result sent to driver
16/06/16 19:55:26 INFO CoarseGrainedExecutorBackend: Got assigned task 399
16/06/16 19:55:26 INFO Executor: Running task 99.0 in stage 3.0 (TID 399)
16/06/16 19:55:26 INFO ShuffleBlockFetcherIterator: Getting 100 non-empty blocks out of 100 blocks
16/06/16 19:55:26 INFO ShuffleBlockFetcherIterator: Started 2 remote fetches in 28 ms
16/06/16 19:55:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:28 INFO PythonRunner: Times: total = 14222, boot = 19, init = 10, finish = 14193
16/06/16 19:55:28 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000080_380' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000080
16/06/16 19:55:28 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000080_380: Committed
16/06/16 19:55:28 INFO Executor: Finished task 80.0 in stage 3.0 (TID 380). 2147 bytes result sent to driver
16/06/16 19:55:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/06/16 19:55:29 INFO PythonRunner: Times: total = 14449, boot = 12, init = 28, finish = 14409
16/06/16 19:55:29 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000082_382' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000082
16/06/16 19:55:29 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000082_382: Committed
16/06/16 19:55:29 INFO Executor: Finished task 82.0 in stage 3.0 (TID 382). 2147 bytes result sent to driver
16/06/16 19:55:29 INFO PythonRunner: Times: total = 18105, boot = 19, init = 43, finish = 18043
16/06/16 19:55:29 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000076_376' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000076
16/06/16 19:55:29 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000076_376: Committed
16/06/16 19:55:29 INFO Executor: Finished task 76.0 in stage 3.0 (TID 376). 2147 bytes result sent to driver
16/06/16 19:55:30 INFO PythonRunner: Times: total = 15555, boot = 17, init = 24, finish = 15514
16/06/16 19:55:30 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000081_381' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000081
16/06/16 19:55:30 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000081_381: Committed
16/06/16 19:55:30 INFO Executor: Finished task 81.0 in stage 3.0 (TID 381). 2147 bytes result sent to driver
16/06/16 19:55:33 INFO PythonRunner: Times: total = 10562, boot = 28, init = 21, finish = 10513
16/06/16 19:55:33 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000095_395' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000095
16/06/16 19:55:33 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000095_395: Committed
16/06/16 19:55:33 INFO Executor: Finished task 95.0 in stage 3.0 (TID 395). 2147 bytes result sent to driver
16/06/16 19:55:33 INFO PythonRunner: Times: total = 12708, boot = 26, init = 80, finish = 12602
16/06/16 19:55:33 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000092_392' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000092
16/06/16 19:55:33 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000092_392: Committed
16/06/16 19:55:33 INFO Executor: Finished task 92.0 in stage 3.0 (TID 392). 2147 bytes result sent to driver
16/06/16 19:55:33 INFO PythonRunner: Times: total = 7249, boot = 13, init = 18, finish = 7218
16/06/16 19:55:33 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000099_399' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000099
16/06/16 19:55:33 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000099_399: Committed
16/06/16 19:55:33 INFO Executor: Finished task 99.0 in stage 3.0 (TID 399). 2147 bytes result sent to driver
16/06/16 19:55:33 INFO PythonRunner: Times: total = 8969, boot = 55, init = 0, finish = 8914
16/06/16 19:55:33 INFO FileOutputCommitter: Saved output of task 'attempt_201606161953_0003_m_000098_398' to file:/home/daniar/documents/SPARK/generated_file/result_py/_temporary/0/task_201606161953_0003_m_000098
16/06/16 19:55:33 INFO SparkHadoopMapRedUtil: attempt_201606161953_0003_m_000098_398: Committed
16/06/16 19:55:33 INFO Executor: Finished task 98.0 in stage 3.0 (TID 398). 2147 bytes result sent to driver
16/06/16 19:55:34 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
