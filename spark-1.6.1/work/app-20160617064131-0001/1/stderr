Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/06/17 06:41:32 INFO CoarseGrainedExecutorBackend: Registered signal handlers for [TERM, HUP, INT]
16/06/17 06:41:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/17 06:41:33 INFO SecurityManager: Changing view acls to: daniar
16/06/17 06:41:33 INFO SecurityManager: Changing modify acls to: daniar
16/06/17 06:41:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(daniar); users with modify permissions: Set(daniar)
16/06/17 06:41:34 INFO SecurityManager: Changing view acls to: daniar
16/06/17 06:41:34 INFO SecurityManager: Changing modify acls to: daniar
16/06/17 06:41:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(daniar); users with modify permissions: Set(daniar)
16/06/17 06:41:35 INFO Slf4jLogger: Slf4jLogger started
16/06/17 06:41:35 INFO Remoting: Starting remoting
16/06/17 06:41:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@192.168.1.10:33387]
16/06/17 06:41:35 INFO Utils: Successfully started service 'sparkExecutorActorSystem' on port 33387.
16/06/17 06:41:35 INFO DiskBlockManager: Created local directory at /tmp/spark-9406d13d-7f60-42f7-bf35-527afcd9013a/executor-d7777437-6b84-4490-aed2-0411bc26bcc4/blockmgr-e44760f7-da09-4ea2-95d7-202a1a8835e4
16/06/17 06:41:35 INFO MemoryStore: MemoryStore started with capacity 511.1 MB
16/06/17 06:41:36 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.1.12:34823
16/06/17 06:41:36 INFO CoarseGrainedExecutorBackend: Daniarrrr
16/06/17 06:41:36 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.1.10:60692
16/06/17 06:41:36 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
16/06/17 06:41:36 INFO Executor: Starting executor ID 1 on host 192.168.1.3
16/06/17 06:41:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56761.
16/06/17 06:41:36 INFO NettyBlockTransferService: Server created on 56761
16/06/17 06:41:36 INFO BlockManagerMaster: Trying to register BlockManager
16/06/17 06:41:36 INFO BlockManagerMaster: Registered BlockManager
16/06/17 06:41:38 INFO CoarseGrainedExecutorBackend: Got assigned task 0
16/06/17 06:41:38 INFO CoarseGrainedExecutorBackend: Got assigned task 3
16/06/17 06:41:38 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
16/06/17 06:41:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/06/17 06:41:38 INFO Executor: Fetching http://192.168.1.12:53307/files/sort.py with timestamp 1466120489796
16/06/17 06:41:39 INFO Utils: Fetching http://192.168.1.12:53307/files/sort.py to /tmp/spark-9406d13d-7f60-42f7-bf35-527afcd9013a/executor-d7777437-6b84-4490-aed2-0411bc26bcc4/spark-f14e614e-1513-4bbe-8519-86aa7a33c4d2/fetchFileTemp1895155049373422143.tmp
16/06/17 06:41:39 INFO Utils: Copying /tmp/spark-9406d13d-7f60-42f7-bf35-527afcd9013a/executor-d7777437-6b84-4490-aed2-0411bc26bcc4/spark-f14e614e-1513-4bbe-8519-86aa7a33c4d2/20840025311466120489796_cache to /home/daniar/documents/SPARK/spark-1.6.1/work/app-20160617064131-0001/1/./sort.py
16/06/17 06:41:39 INFO TorrentBroadcast: Started reading broadcast variable 1
16/06/17 06:41:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 3.7 KB)
16/06/17 06:41:40 INFO TorrentBroadcast: Reading broadcast variable 1 took 1144 ms
16/06/17 06:41:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.1 KB, free 9.8 KB)
16/06/17 06:41:41 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:0+3203777
16/06/17 06:41:41 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:9611331+3203777
16/06/17 06:41:41 INFO TorrentBroadcast: Started reading broadcast variable 0
16/06/17 06:41:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.8 KB, free 31.6 KB)
16/06/17 06:41:41 INFO TorrentBroadcast: Reading broadcast variable 0 took 30 ms
16/06/17 06:41:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 315.4 KB, free 347.0 KB)
16/06/17 06:41:42 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
16/06/17 06:41:42 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
16/06/17 06:41:42 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
16/06/17 06:41:42 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
16/06/17 06:41:42 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
16/06/17 06:41:46 INFO PythonRunner: Times: total = 4413, boot = 663, init = 150, finish = 3600
16/06/17 06:41:46 INFO PythonRunner: Times: total = 4582, boot = 658, init = 127, finish = 3797
16/06/17 06:41:46 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 2129 bytes result sent to driver
16/06/17 06:41:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2129 bytes result sent to driver
16/06/17 06:41:46 INFO CoarseGrainedExecutorBackend: Got assigned task 7
16/06/17 06:41:46 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
16/06/17 06:41:46 INFO CoarseGrainedExecutorBackend: Got assigned task 9
16/06/17 06:41:46 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
16/06/17 06:41:46 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:22426439+3203777
16/06/17 06:41:46 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:28833993+3203777
16/06/17 06:41:50 INFO PythonRunner: Times: total = 3543, boot = -365, init = 408, finish = 3500
16/06/17 06:41:50 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 2129 bytes result sent to driver
16/06/17 06:41:50 INFO CoarseGrainedExecutorBackend: Got assigned task 16
16/06/17 06:41:50 INFO Executor: Running task 16.0 in stage 0.0 (TID 16)
16/06/17 06:41:50 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:51260432+3203777
16/06/17 06:41:50 INFO PythonRunner: Times: total = 3661, boot = -506, init = 513, finish = 3654
16/06/17 06:41:50 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 2129 bytes result sent to driver
16/06/17 06:41:50 INFO CoarseGrainedExecutorBackend: Got assigned task 17
16/06/17 06:41:50 INFO Executor: Running task 17.0 in stage 0.0 (TID 17)
16/06/17 06:41:50 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:54464209+3203777
16/06/17 06:41:53 INFO PythonRunner: Times: total = 3050, boot = -66, init = 110, finish = 3006
16/06/17 06:41:53 INFO Executor: Finished task 17.0 in stage 0.0 (TID 17). 2129 bytes result sent to driver
16/06/17 06:41:53 INFO CoarseGrainedExecutorBackend: Got assigned task 20
16/06/17 06:41:53 INFO Executor: Running task 20.0 in stage 0.0 (TID 20)
16/06/17 06:41:53 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:64075540+3203777
16/06/17 06:41:54 INFO PythonRunner: Times: total = 3352, boot = -24, init = 39, finish = 3337
16/06/17 06:41:54 INFO Executor: Finished task 16.0 in stage 0.0 (TID 16). 2129 bytes result sent to driver
16/06/17 06:41:54 INFO CoarseGrainedExecutorBackend: Got assigned task 22
16/06/17 06:41:54 INFO Executor: Running task 22.0 in stage 0.0 (TID 22)
16/06/17 06:41:54 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:70483094+3203777
16/06/17 06:41:57 INFO PythonRunner: Times: total = 3140, boot = -58, init = 68, finish = 3130
16/06/17 06:41:57 INFO Executor: Finished task 20.0 in stage 0.0 (TID 20). 2129 bytes result sent to driver
16/06/17 06:41:57 INFO CoarseGrainedExecutorBackend: Got assigned task 26
16/06/17 06:41:57 INFO Executor: Running task 26.0 in stage 0.0 (TID 26)
16/06/17 06:41:57 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:83298202+3203777
16/06/17 06:41:57 INFO PythonRunner: Times: total = 3307, boot = -41, init = 59, finish = 3289
16/06/17 06:41:57 INFO Executor: Finished task 22.0 in stage 0.0 (TID 22). 2129 bytes result sent to driver
16/06/17 06:41:57 INFO CoarseGrainedExecutorBackend: Got assigned task 29
16/06/17 06:41:57 INFO Executor: Running task 29.0 in stage 0.0 (TID 29)
16/06/17 06:41:57 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:92909533+3203777
16/06/17 06:42:00 INFO PythonRunner: Times: total = 3296, boot = -49, init = 57, finish = 3288
16/06/17 06:42:00 INFO Executor: Finished task 26.0 in stage 0.0 (TID 26). 2129 bytes result sent to driver
16/06/17 06:42:00 INFO CoarseGrainedExecutorBackend: Got assigned task 30
16/06/17 06:42:00 INFO Executor: Running task 30.0 in stage 0.0 (TID 30)
16/06/17 06:42:00 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:96113310+3203777
16/06/17 06:42:00 INFO PythonRunner: Times: total = 3364, boot = -100, init = 115, finish = 3349
16/06/17 06:42:00 INFO Executor: Finished task 29.0 in stage 0.0 (TID 29). 2129 bytes result sent to driver
16/06/17 06:42:00 INFO CoarseGrainedExecutorBackend: Got assigned task 34
16/06/17 06:42:00 INFO Executor: Running task 34.0 in stage 0.0 (TID 34)
16/06/17 06:42:00 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:108928418+3203777
16/06/17 06:42:03 INFO PythonRunner: Times: total = 3489, boot = 3, init = 13, finish = 3473
16/06/17 06:42:03 INFO Executor: Finished task 30.0 in stage 0.0 (TID 30). 2129 bytes result sent to driver
16/06/17 06:42:03 INFO CoarseGrainedExecutorBackend: Got assigned task 38
16/06/17 06:42:03 INFO Executor: Running task 38.0 in stage 0.0 (TID 38)
16/06/17 06:42:03 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:121743526+3203777
16/06/17 06:42:04 INFO PythonRunner: Times: total = 3537, boot = -42, init = 89, finish = 3490
16/06/17 06:42:04 INFO Executor: Finished task 34.0 in stage 0.0 (TID 34). 2129 bytes result sent to driver
16/06/17 06:42:06 INFO PythonRunner: Times: total = 2320, boot = -45, init = 52, finish = 2313
16/06/17 06:42:06 INFO Executor: Finished task 38.0 in stage 0.0 (TID 38). 2129 bytes result sent to driver
16/06/17 06:42:06 INFO CoarseGrainedExecutorBackend: Got assigned task 40
16/06/17 06:42:06 INFO Executor: Running task 0.0 in stage 1.0 (TID 40)
16/06/17 06:42:06 INFO CoarseGrainedExecutorBackend: Got assigned task 43
16/06/17 06:42:06 INFO Executor: Running task 3.0 in stage 1.0 (TID 43)
16/06/17 06:42:06 INFO TorrentBroadcast: Started reading broadcast variable 2
16/06/17 06:42:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 350.7 KB)
16/06/17 06:42:06 INFO TorrentBroadcast: Reading broadcast variable 2 took 32 ms
16/06/17 06:42:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.9 KB, free 356.5 KB)
16/06/17 06:42:06 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:0+3203777
16/06/17 06:42:06 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:9611331+3203777
16/06/17 06:42:10 INFO PythonRunner: Times: total = 3511, boot = -2072, init = 2141, finish = 3442
16/06/17 06:42:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 40). 2275 bytes result sent to driver
16/06/17 06:42:10 INFO CoarseGrainedExecutorBackend: Got assigned task 47
16/06/17 06:42:10 INFO Executor: Running task 7.0 in stage 1.0 (TID 47)
16/06/17 06:42:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:22426439+3203777
16/06/17 06:42:10 INFO PythonRunner: Times: total = 3907, boot = -296, init = 363, finish = 3840
16/06/17 06:42:10 INFO Executor: Finished task 3.0 in stage 1.0 (TID 43). 2339 bytes result sent to driver
16/06/17 06:42:10 INFO CoarseGrainedExecutorBackend: Got assigned task 50
16/06/17 06:42:10 INFO Executor: Running task 10.0 in stage 1.0 (TID 50)
16/06/17 06:42:10 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:32037770+3203777
16/06/17 06:42:13 INFO PythonRunner: Times: total = 3683, boot = 0, init = 6, finish = 3677
16/06/17 06:42:13 INFO Executor: Finished task 7.0 in stage 1.0 (TID 47). 2296 bytes result sent to driver
16/06/17 06:42:13 INFO CoarseGrainedExecutorBackend: Got assigned task 53
16/06/17 06:42:13 INFO Executor: Running task 13.0 in stage 1.0 (TID 53)
16/06/17 06:42:13 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:41649101+3203777
16/06/17 06:42:13 INFO PythonRunner: Times: total = 3439, boot = 18, init = 1, finish = 3420
16/06/17 06:42:13 INFO Executor: Finished task 10.0 in stage 1.0 (TID 50). 2344 bytes result sent to driver
16/06/17 06:42:13 INFO CoarseGrainedExecutorBackend: Got assigned task 54
16/06/17 06:42:13 INFO Executor: Running task 14.0 in stage 1.0 (TID 54)
16/06/17 06:42:13 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:44852878+3203777
16/06/17 06:42:17 INFO PythonRunner: Times: total = 3588, boot = 9, init = 7, finish = 3572
16/06/17 06:42:17 INFO Executor: Finished task 13.0 in stage 1.0 (TID 53). 2291 bytes result sent to driver
16/06/17 06:42:17 INFO CoarseGrainedExecutorBackend: Got assigned task 59
16/06/17 06:42:17 INFO Executor: Running task 19.0 in stage 1.0 (TID 59)
16/06/17 06:42:17 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:60871763+3203777
16/06/17 06:42:17 INFO PythonRunner: Times: total = 3762, boot = -24, init = 66, finish = 3720
16/06/17 06:42:17 INFO Executor: Finished task 14.0 in stage 1.0 (TID 54). 2314 bytes result sent to driver
16/06/17 06:42:17 INFO CoarseGrainedExecutorBackend: Got assigned task 61
16/06/17 06:42:17 INFO Executor: Running task 21.0 in stage 1.0 (TID 61)
16/06/17 06:42:17 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:67279317+3203777
16/06/17 06:42:20 INFO PythonRunner: Times: total = 3358, boot = -10, init = 56, finish = 3312
16/06/17 06:42:20 INFO Executor: Finished task 19.0 in stage 1.0 (TID 59). 2291 bytes result sent to driver
16/06/17 06:42:20 INFO CoarseGrainedExecutorBackend: Got assigned task 64
16/06/17 06:42:20 INFO Executor: Running task 24.0 in stage 1.0 (TID 64)
16/06/17 06:42:20 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:76890648+3203777
16/06/17 06:42:21 INFO PythonRunner: Times: total = 3717, boot = 5, init = 7, finish = 3705
16/06/17 06:42:21 INFO Executor: Finished task 21.0 in stage 1.0 (TID 61). 2248 bytes result sent to driver
16/06/17 06:42:21 INFO CoarseGrainedExecutorBackend: Got assigned task 67
16/06/17 06:42:21 INFO Executor: Running task 27.0 in stage 1.0 (TID 67)
16/06/17 06:42:21 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:86501979+3203777
16/06/17 06:42:24 INFO PythonRunner: Times: total = 3486, boot = -4, init = 30, finish = 3460
16/06/17 06:42:24 INFO Executor: Finished task 24.0 in stage 1.0 (TID 64). 2309 bytes result sent to driver
16/06/17 06:42:24 INFO CoarseGrainedExecutorBackend: Got assigned task 70
16/06/17 06:42:24 INFO Executor: Running task 30.0 in stage 1.0 (TID 70)
16/06/17 06:42:24 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:96113310+3203777
16/06/17 06:42:24 INFO PythonRunner: Times: total = 3455, boot = -7, init = 14, finish = 3448
16/06/17 06:42:24 INFO Executor: Finished task 27.0 in stage 1.0 (TID 67). 2309 bytes result sent to driver
16/06/17 06:42:24 INFO CoarseGrainedExecutorBackend: Got assigned task 72
16/06/17 06:42:24 INFO Executor: Running task 32.0 in stage 1.0 (TID 72)
16/06/17 06:42:24 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:102520864+3203777
16/06/17 06:42:28 INFO PythonRunner: Times: total = 3962, boot = -9, init = 26, finish = 3945
16/06/17 06:42:28 INFO Executor: Finished task 30.0 in stage 1.0 (TID 70). 2251 bytes result sent to driver
16/06/17 06:42:28 INFO CoarseGrainedExecutorBackend: Got assigned task 76
16/06/17 06:42:28 INFO Executor: Running task 36.0 in stage 1.0 (TID 76)
16/06/17 06:42:28 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:115335972+3203777
16/06/17 06:42:28 INFO PythonRunner: Times: total = 3827, boot = -32, init = 61, finish = 3798
16/06/17 06:42:28 INFO Executor: Finished task 32.0 in stage 1.0 (TID 72). 2253 bytes result sent to driver
16/06/17 06:42:28 INFO CoarseGrainedExecutorBackend: Got assigned task 79
16/06/17 06:42:28 INFO Executor: Running task 39.0 in stage 1.0 (TID 79)
16/06/17 06:42:28 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:124947303+3203787
16/06/17 06:42:31 INFO PythonRunner: Times: total = 2831, boot = -13, init = 51, finish = 2793
16/06/17 06:42:31 INFO Executor: Finished task 36.0 in stage 1.0 (TID 76). 2286 bytes result sent to driver
16/06/17 06:42:31 INFO PythonRunner: Times: total = 2380, boot = -16, init = 28, finish = 2368
16/06/17 06:42:31 INFO Executor: Finished task 39.0 in stage 1.0 (TID 79). 2320 bytes result sent to driver
16/06/17 06:42:32 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
