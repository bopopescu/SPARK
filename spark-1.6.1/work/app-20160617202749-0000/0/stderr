Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/06/17 20:27:50 INFO CoarseGrainedExecutorBackend: Registered signal handlers for [TERM, HUP, INT]
16/06/17 20:27:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/17 20:27:51 INFO SecurityManager: Changing view acls to: daniar
16/06/17 20:27:51 INFO SecurityManager: Changing modify acls to: daniar
16/06/17 20:27:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(daniar); users with modify permissions: Set(daniar)
16/06/17 20:27:52 INFO SecurityManager: Changing view acls to: daniar
16/06/17 20:27:52 INFO SecurityManager: Changing modify acls to: daniar
16/06/17 20:27:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(daniar); users with modify permissions: Set(daniar)
16/06/17 20:27:52 INFO Slf4jLogger: Slf4jLogger started
16/06/17 20:27:52 INFO Remoting: Starting remoting
16/06/17 20:27:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@192.168.1.11:40631]
16/06/17 20:27:52 INFO Utils: Successfully started service 'sparkExecutorActorSystem' on port 40631.
16/06/17 20:27:53 INFO DiskBlockManager: Created local directory at /tmp/spark-44afae56-fc36-416b-92ce-6fc0d23e8ad0/executor-457fae30-b937-482b-8ebc-70efcc622628/blockmgr-d77a1a09-79f1-4512-be3b-684102a6cbd4
16/06/17 20:27:53 INFO MemoryStore: MemoryStore started with capacity 511.1 MB
16/06/17 20:27:53 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.1.12:37698
16/06/17 20:27:53 INFO CoarseGrainedExecutorBackend: Daniarrrr null
16/06/17 20:27:53 INFO CoarseGrainedExecutorBackend: Daniarrrr 2
16/06/17 20:27:53 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.1.11:54210
16/06/17 20:27:53 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
16/06/17 20:27:53 INFO Executor: Starting executor ID 0 on host 192.168.1.10
16/06/17 20:27:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48254.
16/06/17 20:27:53 INFO NettyBlockTransferService: Server created on 48254
16/06/17 20:27:53 INFO BlockManagerMaster: Trying to register BlockManager
16/06/17 20:27:53 INFO BlockManagerMaster: Registered BlockManager
16/06/17 20:27:53 INFO CoarseGrainedExecutorBackend: Got assigned task 0
16/06/17 20:27:53 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:27:53 INFO CoarseGrainedExecutorBackend: Got assigned task 1
16/06/17 20:27:53 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:27:53 INFO CoarseGrainedExecutorBackend: Got assigned task 2
16/06/17 20:27:53 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:27:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/06/17 20:27:53 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/06/17 20:27:53 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
16/06/17 20:27:53 INFO Executor: Fetching http://192.168.1.12:35986/files/sort.py with timestamp 1466170068548
16/06/17 20:27:54 INFO Utils: Fetching http://192.168.1.12:35986/files/sort.py to /tmp/spark-44afae56-fc36-416b-92ce-6fc0d23e8ad0/executor-457fae30-b937-482b-8ebc-70efcc622628/spark-d8e90a9e-033c-42ad-99b5-3a768bcf93ea/fetchFileTemp8890617278234510173.tmp
16/06/17 20:27:54 INFO Utils: Copying /tmp/spark-44afae56-fc36-416b-92ce-6fc0d23e8ad0/executor-457fae30-b937-482b-8ebc-70efcc622628/spark-d8e90a9e-033c-42ad-99b5-3a768bcf93ea/118672281466170068548_cache to /home/daniar/documents/SPARK/spark-1.6.1/work/app-20160617202749-0000/0/./sort.py
16/06/17 20:27:54 INFO TorrentBroadcast: Started reading broadcast variable 1
16/06/17 20:27:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 3.7 KB)
16/06/17 20:27:54 INFO TorrentBroadcast: Reading broadcast variable 1 took 434 ms
16/06/17 20:27:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.1 KB, free 9.8 KB)
16/06/17 20:27:55 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:0+12815109
16/06/17 20:27:55 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:12815109+12815109
16/06/17 20:27:55 INFO TorrentBroadcast: Started reading broadcast variable 0
16/06/17 20:27:55 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:25630218+12815109
16/06/17 20:27:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.8 KB, free 31.6 KB)
16/06/17 20:27:55 INFO TorrentBroadcast: Reading broadcast variable 0 took 12 ms
16/06/17 20:27:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 315.4 KB, free 347.0 KB)
16/06/17 20:27:55 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
16/06/17 20:27:55 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
16/06/17 20:27:55 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
16/06/17 20:27:55 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
16/06/17 20:27:55 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
16/06/17 20:28:03 INFO PythonRunner: Times: total = 7840, boot = 321, init = 129, finish = 7390
16/06/17 20:28:03 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 2130 bytes result sent to driver
16/06/17 20:28:03 INFO CoarseGrainedExecutorBackend: Got assigned task 6
16/06/17 20:28:03 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:28:03 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
16/06/17 20:28:03 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:76890654+12815109
16/06/17 20:28:03 INFO PythonRunner: Times: total = 8077, boot = 317, init = 119, finish = 7641
16/06/17 20:28:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2130 bytes result sent to driver
16/06/17 20:28:03 INFO CoarseGrainedExecutorBackend: Got assigned task 7
16/06/17 20:28:03 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:28:03 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
16/06/17 20:28:03 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:89705763+12815109
16/06/17 20:28:03 INFO PythonRunner: Times: total = 8325, boot = 308, init = 121, finish = 7896
16/06/17 20:28:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2130 bytes result sent to driver
16/06/17 20:28:03 INFO CoarseGrainedExecutorBackend: Got assigned task 9
16/06/17 20:28:03 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:28:03 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
16/06/17 20:28:03 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:115335981+12815109
16/06/17 20:28:11 INFO PythonRunner: Times: total = 7499, boot = -52, init = 57, finish = 7494
16/06/17 20:28:11 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 2130 bytes result sent to driver
16/06/17 20:28:11 INFO PythonRunner: Times: total = 7095, boot = -17, init = 22, finish = 7090
16/06/17 20:28:11 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 2130 bytes result sent to driver
16/06/17 20:28:11 INFO PythonRunner: Times: total = 7383, boot = -20, init = 37, finish = 7366
16/06/17 20:28:11 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 2130 bytes result sent to driver
16/06/17 20:28:11 INFO CoarseGrainedExecutorBackend: Got assigned task 11
16/06/17 20:28:11 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:28:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 11)
16/06/17 20:28:11 INFO TorrentBroadcast: Started reading broadcast variable 2
16/06/17 20:28:11 INFO CoarseGrainedExecutorBackend: Got assigned task 13
16/06/17 20:28:11 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:28:11 INFO Executor: Running task 3.0 in stage 1.0 (TID 13)
16/06/17 20:28:11 INFO CoarseGrainedExecutorBackend: Got assigned task 14
16/06/17 20:28:11 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:28:11 INFO Executor: Running task 4.0 in stage 1.0 (TID 14)
16/06/17 20:28:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 350.7 KB)
16/06/17 20:28:11 INFO TorrentBroadcast: Reading broadcast variable 2 took 26 ms
16/06/17 20:28:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.9 KB, free 356.5 KB)
16/06/17 20:28:11 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:51260436+12815109
16/06/17 20:28:11 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:12815109+12815109
16/06/17 20:28:11 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:38445327+12815109
16/06/17 20:28:18 INFO PythonRunner: Times: total = 7474, boot = -228, init = 240, finish = 7462
16/06/17 20:28:18 INFO Executor: Finished task 4.0 in stage 1.0 (TID 14). 2315 bytes result sent to driver
16/06/17 20:28:18 INFO CoarseGrainedExecutorBackend: Got assigned task 15
16/06/17 20:28:18 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:28:18 INFO Executor: Running task 5.0 in stage 1.0 (TID 15)
16/06/17 20:28:18 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:64075545+12815109
16/06/17 20:28:19 INFO PythonRunner: Times: total = 7876, boot = -151, init = 163, finish = 7864
16/06/17 20:28:19 INFO Executor: Finished task 1.0 in stage 1.0 (TID 11). 2318 bytes result sent to driver
16/06/17 20:28:19 INFO CoarseGrainedExecutorBackend: Got assigned task 17
16/06/17 20:28:19 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:28:19 INFO Executor: Running task 7.0 in stage 1.0 (TID 17)
16/06/17 20:28:19 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:89705763+12815109
16/06/17 20:28:20 INFO PythonRunner: Times: total = 9257, boot = -183, init = 237, finish = 9203
16/06/17 20:28:20 INFO Executor: Finished task 3.0 in stage 1.0 (TID 13). 2302 bytes result sent to driver
16/06/17 20:28:20 INFO CoarseGrainedExecutorBackend: Got assigned task 19
16/06/17 20:28:20 INFO CoarseGrainedExecutorBackend: daniarr ---- executor task org.apache.spark.executor.Executor@1d5864d5
16/06/17 20:28:20 INFO Executor: Running task 9.0 in stage 1.0 (TID 19)
16/06/17 20:28:20 INFO HadoopRDD: Input split: file:/home/daniar/documents/SPARK/generated_file/list_int:115335981+12815109
16/06/17 20:28:26 INFO PythonRunner: Times: total = 7874, boot = -17, init = 21, finish = 7870
16/06/17 20:28:26 INFO Executor: Finished task 5.0 in stage 1.0 (TID 15). 2330 bytes result sent to driver
16/06/17 20:28:27 INFO PythonRunner: Times: total = 7939, boot = 1, init = 5, finish = 7933
16/06/17 20:28:27 INFO Executor: Finished task 7.0 in stage 1.0 (TID 17). 2285 bytes result sent to driver
16/06/17 20:28:27 INFO PythonRunner: Times: total = 7333, boot = -12, init = 19, finish = 7326
16/06/17 20:28:27 INFO Executor: Finished task 9.0 in stage 1.0 (TID 19). 2292 bytes result sent to driver
16/06/17 20:28:28 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
