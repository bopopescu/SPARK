DANIAR
NOTE: SPARK_PREPEND_CLASSES is set, placing locally compiled Spark classes ahead of assembly.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/07/20 11:22:59 INFO SparkContext: Running Spark version 1.6.1
16/07/20 11:23:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/07/20 11:23:00 INFO SecurityManager: Changing view acls to: daniar
16/07/20 11:23:00 INFO SecurityManager: Changing modify acls to: daniar
16/07/20 11:23:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(daniar); users with modify permissions: Set(daniar)
16/07/20 11:23:00 INFO Utils: Successfully started service 'sparkDriver' on port 33842.
16/07/20 11:23:01 INFO Slf4jLogger: Slf4jLogger started
16/07/20 11:23:01 INFO Remoting: Starting remoting
16/07/20 11:23:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@155.98.38.147:34926]
16/07/20 11:23:01 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 34926.
16/07/20 11:23:01 INFO SparkEnv: Registering MapOutputTracker
16/07/20 11:23:01 INFO SparkEnv: Registering BlockManagerMaster
16/07/20 11:23:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-31afc5c3-650e-4296-8ed1-bcfdee46deaa
16/07/20 11:23:01 INFO MemoryStore: MemoryStore started with capacity 511.1 MB
16/07/20 11:23:01 INFO SparkEnv: Registering OutputCommitCoordinator
16/07/20 11:23:02 INFO Server: jetty-8.y.z-SNAPSHOT
16/07/20 11:23:02 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
16/07/20 11:23:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/07/20 11:23:02 INFO SparkUI: Started SparkUI at http://155.98.38.147:4040
Java HotSpot(TM) Server VM warning: You have loaded library /tmp/libnetty-transport-native-epoll643704170982047261.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
16/07/20 11:23:02 INFO HttpFileServer: HTTP File server directory is /tmp/spark-de9a2c77-a2fe-4aa1-a108-cad307875306/httpd-cde1b0a6-f553-4643-aad9-3c049ae8eee6
16/07/20 11:23:02 INFO HttpServer: Starting HTTP Server
16/07/20 11:23:02 INFO Server: jetty-8.y.z-SNAPSHOT
16/07/20 11:23:02 INFO AbstractConnector: Started SocketConnector@0.0.0.0:54023
16/07/20 11:23:02 INFO Utils: Successfully started service 'HTTP file server' on port 54023.
16/07/20 11:23:02 INFO Utils: Copying /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py to /tmp/spark-de9a2c77-a2fe-4aa1-a108-cad307875306/userFiles-93ba6d0f-ed9a-45e5-9139-f07a79f7f35f/sort.py
16/07/20 11:23:02 INFO SparkContext: Added file file:/proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py at http://155.98.38.147:54023/files/sort.py with timestamp 1469035382442
16/07/20 11:23:02 INFO SparkDeploySchedulerBackend: DaniarrronStartCoarse
16/07/20 11:23:02 INFO AppClient$ClientEndpoint: Connecting to master spark://n1.testspark.cs331-uc.emulab.net:7077...
16/07/20 11:23:03 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20160720112303-0001
16/07/20 11:23:03 INFO TaskSchedulerImpl: Starting speculative execution thread
16/07/20 11:23:03 INFO AppClient$ClientEndpoint: Executor added: app-20160720112303-0001/0 on worker-20160720112048-155.98.38.98-54351 (155.98.38.98:54351) with 2 cores
16/07/20 11:23:03 INFO SparkDeploySchedulerBackend: Granted executor ID app-20160720112303-0001/0 on hostPort 155.98.38.98:54351 with 2 cores, 1024.0 MB RAM
16/07/20 11:23:03 INFO AppClient$ClientEndpoint: Executor added: app-20160720112303-0001/1 on worker-20160720112050-155.98.38.91-58228 (155.98.38.91:58228) with 2 cores
16/07/20 11:23:03 INFO SparkDeploySchedulerBackend: Granted executor ID app-20160720112303-0001/1 on hostPort 155.98.38.91:58228 with 2 cores, 1024.0 MB RAM
16/07/20 11:23:03 INFO AppClient$ClientEndpoint: Executor added: app-20160720112303-0001/2 on worker-20160720112049-155.98.38.100-46392 (155.98.38.100:46392) with 2 cores
16/07/20 11:23:03 INFO SparkDeploySchedulerBackend: Granted executor ID app-20160720112303-0001/2 on hostPort 155.98.38.100:46392 with 2 cores, 1024.0 MB RAM
16/07/20 11:23:03 INFO AppClient$ClientEndpoint: Executor updated: app-20160720112303-0001/1 is now RUNNING
16/07/20 11:23:03 INFO AppClient$ClientEndpoint: Executor updated: app-20160720112303-0001/0 is now RUNNING
16/07/20 11:23:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48533.
16/07/20 11:23:03 INFO NettyBlockTransferService: Server created on 48533
16/07/20 11:23:03 INFO AppClient$ClientEndpoint: Executor updated: app-20160720112303-0001/2 is now RUNNING
16/07/20 11:23:03 INFO BlockManagerMaster: Trying to register BlockManager
16/07/20 11:23:03 INFO BlockManagerMasterEndpoint: Registering block manager 155.98.38.147:48533 with 511.1 MB RAM, BlockManagerId(driver, 155.98.38.147, 48533)
16/07/20 11:23:03 INFO BlockManagerMaster: Registered BlockManager
16/07/20 11:23:03 INFO EventLoggingListener: Logging events to file:/proj/cs331-uc/daniar/SPARK/spark-1.6.1/../generated_driver_log/app-20160720112303-0001
16/07/20 11:23:03 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:03 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:03 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:03 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:03 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:03 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:03 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:04 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:04 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:04 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:04 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:04 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:04 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:04 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:04 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:04 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:04 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:05 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:05 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:05 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:05 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:05 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:05 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:05 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:05 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:05 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:05 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend:  CoarseGrainedSchedulerBackendScala: Daniarrrr --- RegisterExecutor null
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: CoarseGrainedSchedulerBackend: martin -- execAdr is null pc491.emulab.net:53176
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (pc491.emulab.net:53176) with ID 1
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: Daniarrrrr --- executorDataMap not contains(executorId)
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: Daniarrrrr --- executorDataMap not contains(executorId)
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend:  CoarseGrainedSchedulerBackendScala: Daniarrrr --- RegisterExecutor null
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: CoarseGrainedSchedulerBackend: martin -- execAdr is null pc498.emulab.net:42802
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (pc498.emulab.net:42802) with ID 0
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: Daniarrrrr --- executorDataMap not contains(executorId)
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: Daniarrrrr --- executorDataMap not contains(executorId)
16/07/20 11:23:06 INFO BlockManagerMasterEndpoint: Registering block manager pc491.emulab.net:52554 with 511.1 MB RAM, BlockManagerId(1, pc491.emulab.net, 52554)
16/07/20 11:23:06 INFO BlockManagerMasterEndpoint: Registering block manager pc498.emulab.net:35393 with 511.1 MB RAM, BlockManagerId(0, pc498.emulab.net, 35393)
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend:  CoarseGrainedSchedulerBackendScala: Daniarrrr --- RegisterExecutor null
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: CoarseGrainedSchedulerBackend: martin -- execAdr is null pc500.emulab.net:39257
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (pc500.emulab.net:39257) with ID 2
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: Daniarrrrr --- executorDataMap not contains(executorId)
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: Daniarrrrr --- executorDataMap not contains(executorId)
16/07/20 11:23:06 INFO BlockManagerMasterEndpoint: Registering block manager pc500.emulab.net:43767 with 511.1 MB RAM, BlockManagerId(2, pc500.emulab.net, 43767)
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: DANIAR DO THE HACK in SparkDeploySchedulerBackend.scala
16/07/20 11:23:06 INFO SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
16/07/20 11:23:07 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
16/07/20 11:23:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 208.3 KB, free 208.3 KB)
16/07/20 11:23:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.8 KB, free 230.0 KB)
16/07/20 11:23:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 155.98.38.147:48533 (size: 21.8 KB, free: 511.1 MB)
16/07/20 11:23:07 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
16/07/20 11:23:07 INFO FileInputFormat: Total input paths to process : 1
16/07/20 11:23:07 INFO SparkContext: Starting job: sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12
16/07/20 11:23:07 INFO DAGScheduler: Got job 0 (sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12) with 3 output partitions
16/07/20 11:23:07 INFO DAGScheduler: Final stage: ResultStage 0 (sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12)
16/07/20 11:23:07 INFO DAGScheduler: Parents of final stage: List()
16/07/20 11:23:07 INFO DAGScheduler: Missing parents: List()
16/07/20 11:23:07 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12), which has no missing parents
16/07/20 11:23:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.1 KB, free 236.2 KB)
16/07/20 11:23:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 239.9 KB)
16/07/20 11:23:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 155.98.38.147:48533 (size: 3.7 KB, free: 511.1 MB)
16/07/20 11:23:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1007
16/07/20 11:23:07 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 0 (PythonRDD[2] at sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12)
16/07/20 11:23:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 3 tasks
16/07/20 11:23:07 INFO TaskSetManager: SAPIIIIIIIIIIIII  TaskSet 0.0
16/07/20 11:23:07 INFO TaskSetManager: Daniar: Important! Starting task 0.0 in stage 0.0 (TID 0, pc491.emulab.net, partition 0,PROCESS_LOCAL, 2208 bytes)
16/07/20 11:23:07 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@1e51f77    ResultTask(0, 0)
16/07/20 11:23:07 INFO TaskSetManager: Daniar: Important! Starting task 1.0 in stage 0.0 (TID 1, pc498.emulab.net, partition 1,PROCESS_LOCAL, 2208 bytes)
16/07/20 11:23:07 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@1a07c6d    ResultTask(0, 1)
16/07/20 11:23:07 INFO TaskSetManager: Daniar: Important! Starting task 2.0 in stage 0.0 (TID 2, pc500.emulab.net, partition 2,PROCESS_LOCAL, 2208 bytes)
16/07/20 11:23:07 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@6ee9c3    ResultTask(0, 2)
16/07/20 11:23:07 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:07 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:07 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on pc491.emulab.net:52554 (size: 3.7 KB, free: 511.1 MB)
16/07/20 11:23:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on pc498.emulab.net:35393 (size: 3.7 KB, free: 511.1 MB)
16/07/20 11:23:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on pc500.emulab.net:43767 (size: 3.7 KB, free: 511.1 MB)
16/07/20 11:23:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on pc491.emulab.net:52554 (size: 21.8 KB, free: 511.1 MB)
16/07/20 11:23:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on pc498.emulab.net:35393 (size: 21.8 KB, free: 511.1 MB)
16/07/20 11:23:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on pc500.emulab.net:43767 (size: 21.8 KB, free: 511.1 MB)
16/07/20 11:23:19 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers0
16/07/20 11:23:19 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11932 ms on pc498.emulab.net (1/3)
16/07/20 11:23:20 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers1
16/07/20 11:23:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12233 ms on pc491.emulab.net (2/3)
16/07/20 11:23:20 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers2
16/07/20 11:23:20 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 12541 ms on pc500.emulab.net (3/3)
16/07/20 11:23:20 INFO DAGScheduler: ResultStage 0 (sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12) finished in 12.577 s
16/07/20 11:23:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/07/20 11:23:20 INFO DAGScheduler: Job 0 finished: sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12, took 12.688874 s
16/07/20 11:23:20 INFO SparkContext: Starting job: sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12
16/07/20 11:23:20 INFO DAGScheduler: Got job 1 (sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12) with 3 output partitions
16/07/20 11:23:20 INFO DAGScheduler: Final stage: ResultStage 1 (sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12)
16/07/20 11:23:20 INFO DAGScheduler: Parents of final stage: List()
16/07/20 11:23:20 INFO DAGScheduler: Missing parents: List()
16/07/20 11:23:20 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[3] at sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12), which has no missing parents
16/07/20 11:23:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.9 KB, free 245.7 KB)
16/07/20 11:23:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 249.4 KB)
16/07/20 11:23:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 155.98.38.147:48533 (size: 3.7 KB, free: 511.1 MB)
16/07/20 11:23:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1007
16/07/20 11:23:20 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (PythonRDD[3] at sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12)
16/07/20 11:23:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
16/07/20 11:23:20 INFO TaskSetManager: SAPIIIIIIIIIIIII  TaskSet 1.0
16/07/20 11:23:20 INFO TaskSetManager: Daniar: Important! Starting task 0.0 in stage 1.0 (TID 3, pc491.emulab.net, partition 0,PROCESS_LOCAL, 2208 bytes)
16/07/20 11:23:20 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@8dbf6b    ResultTask(1, 0)
16/07/20 11:23:20 INFO TaskSetManager: Daniar: Important! Starting task 1.0 in stage 1.0 (TID 4, pc498.emulab.net, partition 1,PROCESS_LOCAL, 2208 bytes)
16/07/20 11:23:20 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@12dbed2    ResultTask(1, 1)
16/07/20 11:23:20 INFO TaskSetManager: Daniar: Important! Starting task 2.0 in stage 1.0 (TID 5, pc500.emulab.net, partition 2,PROCESS_LOCAL, 2208 bytes)
16/07/20 11:23:20 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@14d004c    ResultTask(1, 2)
16/07/20 11:23:20 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:20 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:20 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on pc498.emulab.net:35393 (size: 3.7 KB, free: 511.1 MB)
16/07/20 11:23:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on pc491.emulab.net:52554 (size: 3.7 KB, free: 511.1 MB)
16/07/20 11:23:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on pc500.emulab.net:43767 (size: 3.7 KB, free: 511.1 MB)
16/07/20 11:23:32 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers1
16/07/20 11:23:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 3) in 11995 ms on pc491.emulab.net (1/3)
16/07/20 11:23:32 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers2
16/07/20 11:23:32 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 5) in 12001 ms on pc500.emulab.net (2/3)
16/07/20 11:23:32 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers0
16/07/20 11:23:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 4) in 12022 ms on pc498.emulab.net (3/3)
16/07/20 11:23:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/07/20 11:23:32 INFO DAGScheduler: ResultStage 1 (sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12) finished in 12.023 s
16/07/20 11:23:32 INFO DAGScheduler: Job 1 finished: sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12, took 12.032597 s
16/07/20 11:23:32 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
16/07/20 11:23:32 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
16/07/20 11:23:32 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
16/07/20 11:23:32 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
16/07/20 11:23:32 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
16/07/20 11:23:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/07/20 11:23:32 INFO SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:-2
16/07/20 11:23:32 INFO DAGScheduler: Registering RDD 5 (sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12)
16/07/20 11:23:32 INFO DAGScheduler: Got job 2 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) with 3 output partitions
16/07/20 11:23:32 INFO DAGScheduler: Final stage: ResultStage 3 (saveAsTextFile at NativeMethodAccessorImpl.java:-2)
16/07/20 11:23:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
16/07/20 11:23:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
16/07/20 11:23:32 INFO DAGScheduler: Submitting ShuffleMapStage 2 (PairwiseRDD[5] at sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12), which has no missing parents
16/07/20 11:23:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.5 KB, free 256.9 KB)
16/07/20 11:23:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.7 KB, free 261.6 KB)
16/07/20 11:23:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 155.98.38.147:48533 (size: 4.7 KB, free: 511.1 MB)
16/07/20 11:23:32 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1007
16/07/20 11:23:32 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 2 (PairwiseRDD[5] at sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12)
16/07/20 11:23:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 3 tasks
16/07/20 11:23:32 INFO TaskSetManager: SAPIIIIIIIIIIIII  TaskSet 2.0
16/07/20 11:23:32 INFO TaskSetManager: Daniar: Important! Starting task 0.0 in stage 2.0 (TID 6, pc491.emulab.net, partition 0,PROCESS_LOCAL, 2197 bytes)
16/07/20 11:23:32 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@119d041    ShuffleMapTask(2, 0)
16/07/20 11:23:32 INFO TaskSetManager: Daniar: Important! Starting task 1.0 in stage 2.0 (TID 7, pc498.emulab.net, partition 1,PROCESS_LOCAL, 2197 bytes)
16/07/20 11:23:32 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@1d53c43    ShuffleMapTask(2, 1)
16/07/20 11:23:32 INFO TaskSetManager: Daniar: Important! Starting task 2.0 in stage 2.0 (TID 8, pc500.emulab.net, partition 2,PROCESS_LOCAL, 2197 bytes)
16/07/20 11:23:32 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@10abfdc    ShuffleMapTask(2, 2)
16/07/20 11:23:32 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:32 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:32 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on pc491.emulab.net:52554 (size: 4.7 KB, free: 511.1 MB)
16/07/20 11:23:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on pc500.emulab.net:43767 (size: 4.7 KB, free: 511.1 MB)
16/07/20 11:23:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on pc498.emulab.net:35393 (size: 4.7 KB, free: 511.1 MB)
16/07/20 11:23:49 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers1
16/07/20 11:23:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 6) in 16638 ms on pc491.emulab.net (1/3)
16/07/20 11:23:49 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers0
16/07/20 11:23:49 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 7) in 16719 ms on pc498.emulab.net (2/3)
16/07/20 11:23:49 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers2
16/07/20 11:23:49 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 8) in 16964 ms on pc500.emulab.net (3/3)
16/07/20 11:23:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/07/20 11:23:49 INFO DAGScheduler: ShuffleMapStage 2 (sortByKey at /proj/cs331-uc/daniar/SPARK/spark-1.6.1/sort.py:12) finished in 16.966 s
16/07/20 11:23:49 INFO DAGScheduler: looking for newly runnable stages
16/07/20 11:23:49 INFO DAGScheduler: running: Set()
16/07/20 11:23:49 INFO DAGScheduler: waiting: Set(ResultStage 3)
16/07/20 11:23:49 INFO DAGScheduler: failed: Set()
16/07/20 11:23:49 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[10] at saveAsTextFile at NativeMethodAccessorImpl.java:-2), which has no missing parents
16/07/20 11:23:49 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 75.0 KB, free 336.6 KB)
16/07/20 11:23:49 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.2 KB, free 363.8 KB)
16/07/20 11:23:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 155.98.38.147:48533 (size: 27.2 KB, free: 511.1 MB)
16/07/20 11:23:49 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1007
16/07/20 11:23:49 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 3 (MapPartitionsRDD[10] at saveAsTextFile at NativeMethodAccessorImpl.java:-2)
16/07/20 11:23:49 INFO TaskSchedulerImpl: Adding task set 3.0 with 3 tasks
16/07/20 11:23:49 INFO TaskSetManager: SAPIIIIIIIIIIIII  TaskSet 3.0
16/07/20 11:23:49 INFO TaskSetManager: Daniar: Important! Starting task 0.0 in stage 3.0 (TID 9, pc491.emulab.net, partition 0,NODE_LOCAL, 1944 bytes)
16/07/20 11:23:49 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@1ddc59c    ResultTask(3, 0)
16/07/20 11:23:49 INFO TaskSetManager: Daniar: Important! Starting task 1.0 in stage 3.0 (TID 10, pc498.emulab.net, partition 1,NODE_LOCAL, 1944 bytes)
16/07/20 11:23:49 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@1f8ddfe    ResultTask(3, 1)
16/07/20 11:23:49 INFO TaskSetManager: Daniar: Important! Starting task 2.0 in stage 3.0 (TID 11, pc500.emulab.net, partition 2,NODE_LOCAL, 1944 bytes)
16/07/20 11:23:49 INFO DAGScheduler: DANIAR DAGScheduler.scala  org.apache.spark.scheduler.TaskInfo@11a2227    ResultTask(3, 2)
16/07/20 11:23:49 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:49 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:49 INFO SparkDeploySchedulerBackend: Daniarrr:  Before assigning any tasks it should be no random assignment [should be printed once]
16/07/20 11:23:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on pc491.emulab.net:52554 (size: 27.2 KB, free: 511.1 MB)
16/07/20 11:23:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on pc500.emulab.net:43767 (size: 27.2 KB, free: 511.1 MB)
16/07/20 11:23:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on pc498.emulab.net:35393 (size: 27.2 KB, free: 511.1 MB)
16/07/20 11:23:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to pc491.emulab.net:53176
16/07/20 11:23:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to pc498.emulab.net:42802
16/07/20 11:23:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to pc500.emulab.net:39257
16/07/20 11:23:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 178 bytes
16/07/20 11:23:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 178 bytes
16/07/20 11:23:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 178 bytes
16/07/20 11:24:05 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers1
16/07/20 11:24:05 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 9) in 15954 ms on pc491.emulab.net (1/3)
16/07/20 11:24:12 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers2
16/07/20 11:24:12 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 11) in 22805 ms on pc500.emulab.net (2/3)
16/07/20 11:24:16 INFO SparkDeploySchedulerBackend: daniarrr -- makeOffers0
16/07/20 11:24:16 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 10) in 27169 ms on pc498.emulab.net (3/3)
16/07/20 11:24:16 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
16/07/20 11:24:16 INFO DAGScheduler: ResultStage 3 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) finished in 27.174 s
16/07/20 11:24:16 INFO DAGScheduler: Job 2 finished: saveAsTextFile at NativeMethodAccessorImpl.java:-2, took 44.249346 s
16/07/20 11:24:16 INFO SparkContext: Invoking stop() from shutdown hook
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/api,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
16/07/20 11:24:17 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
16/07/20 11:24:17 INFO SparkUI: Stopped Spark web UI at http://155.98.38.147:4040
16/07/20 11:24:17 INFO SparkDeploySchedulerBackend: Shutting down all executors
16/07/20 11:24:17 INFO SparkDeploySchedulerBackend: Asking each executor to shut down
16/07/20 11:24:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/07/20 11:24:17 INFO MemoryStore: MemoryStore cleared
16/07/20 11:24:17 INFO BlockManager: BlockManager stopped
16/07/20 11:24:17 INFO BlockManagerMaster: BlockManagerMaster stopped
16/07/20 11:24:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/07/20 11:24:17 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/07/20 11:24:17 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/07/20 11:24:17 INFO SparkContext: Successfully stopped SparkContext
16/07/20 11:24:17 INFO ShutdownHookManager: Shutdown hook called
16/07/20 11:24:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-de9a2c77-a2fe-4aa1-a108-cad307875306/httpd-cde1b0a6-f553-4643-aad9-3c049ae8eee6
16/07/20 11:24:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-de9a2c77-a2fe-4aa1-a108-cad307875306
16/07/20 11:24:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-de9a2c77-a2fe-4aa1-a108-cad307875306/pyspark-8f7693b5-ed37-4182-a607-754bc2342c0e
